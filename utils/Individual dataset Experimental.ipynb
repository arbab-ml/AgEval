{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modifying for fruits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import time\n",
    "from PIL import Image\n",
    "nest_asyncio.apply()\n",
    "global all_data_results\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from fuzzywuzzy import process\n",
    "import io\n",
    "# Set the base directory\n",
    "base_directory = 'data/fruits-images-dataset-object-detection/Train File/Train File'\n",
    "# FOR API\n",
    "max_requests_per_half_minute = 20\n",
    "\n",
    "num_instances_per_class=10\n",
    "\n",
    "# Define the list of expected class labels\n",
    "expected_classes = ['Banana', 'Jackfruit', 'Mango', 'Litchi', 'Hog Plum', 'Papaya', 'Grapes', 'Apple', 'Orange', 'Guava']\n",
    "\n",
    "# Create empty lists to store file paths and labels\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(base_directory):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.jpeg'):\n",
    "        # Extract the label from the filename\n",
    "        label = filename.split('_')[1].split('.')[0]\n",
    "        \n",
    "        # Find the closest match among expected classes using fuzzy matching\n",
    "        closest_match = process.extractOne(label, expected_classes)\n",
    "        \n",
    "        # Get the standardized label (closest match)\n",
    "        standardized_label = closest_match[0]\n",
    "        \n",
    "        # Append the file path and standardized label to the respective lists\n",
    "        file_paths.append(os.path.join(base_directory, filename))\n",
    "        labels.append(standardized_label)\n",
    "\n",
    "# Create a dataframe from the lists\n",
    "data = pd.DataFrame({0: file_paths, 1: labels})\n",
    "\n",
    "# Get the unique classes\n",
    "unique_classes = data[1].unique()\n",
    "\n",
    "# Create a new dataframe with sampled data\n",
    "sampled_data = pd.DataFrame(columns=[0, 1])\n",
    "\n",
    "# Sample uniformly from each class\n",
    "for cls in unique_classes:\n",
    "    class_data = data[data[1] == cls].sample(n=num_instances_per_class, random_state=42)\n",
    "    sampled_data = pd.concat([sampled_data, class_data], ignore_index=True)\n",
    "\n",
    "# Shuffle the sampled data\n",
    "all_data = shuffle(sampled_data, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def load_image(image_path: str) -> str:\n",
    "    \"\"\"Load image from file and encode it as base64.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model =\"gpt-4o-2024-05-13\" #\"gpt-4-turbo\"\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "vision_prompt = f\"\"\"\n",
    "Given the image, identify the class. Use the following list of possible classes for your prediction It should be one of the : {expected_classes}. Be attentive to subtle details as some classes may appear similar. Provide your answer in the following JSON format:\n",
    "{{\"prediction\": \"class_name\"}}\n",
    "Replace \"class_name\" with the appropriate class from the list above based on your analysis of the image.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "request_times = []\n",
    "\n",
    "async def get_image_informations(session, inputs: dict) -> dict:\n",
    "    \"\"\"Invoke model with image and prompt.\"\"\"\n",
    "    global request_times\n",
    "    \n",
    "    while True:\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Remove old request times outside the current time window\n",
    "        while request_times and request_times[0] <= current_time - 30:\n",
    "            request_times.pop(0)\n",
    "        \n",
    "        if len(request_times) < max_requests_per_half_minute:\n",
    "            request_times.append(current_time)\n",
    "            break\n",
    "        else:\n",
    "            # If the rate limit is exceeded, wait for a short duration before checking again\n",
    "            await asyncio.sleep(1)\n",
    "    \n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"response_format\":{ \"type\": \"json_object\" },\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": vision_prompt},\n",
    "                    *inputs['examples'],\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{inputs['image']}\",\n",
    "                            \"detail\": \"low\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "    async with session.post(url, headers=headers, json=payload) as response:\n",
    "        result = await response.json()\n",
    "        print(result)\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            return result\n",
    "        else:\n",
    "            raise Exception(\"Unexpected API response format\")\n",
    "\n",
    "async def process_image(session, i, number_of_shots, all_data_results):\n",
    "    try:\n",
    "        image_path = all_data[0][i]\n",
    "        image_base64 = load_image(image_path)\n",
    "        examples = []\n",
    "\n",
    "        # Get the number of rows in all_data\n",
    "        num_rows = len(all_data)\n",
    "\n",
    "        # Select random indices from the dataframe\n",
    "        random_indices = random.sample(range(num_rows), number_of_shots)\n",
    "\n",
    "        for j in random_indices:\n",
    "            example_image_path = all_data[0][j]\n",
    "            example_image_base64 = load_image(example_image_path)\n",
    "            examples.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{example_image_base64}\", \"detail\": \"low\"}})\n",
    "            examples.append({\"type\": \"text\", \"text\": f'{{\"prediction\": \"{all_data.at[j, 1]}\"}}' })\n",
    "\n",
    "\n",
    "        result = await get_image_informations(session, {\"image\": image_base64, \"examples\": examples})\n",
    "        prediction = result[\"choices\"][0]['message']['content']\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = json.loads(prediction)['prediction']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {all_data[0][i]}: {str(e)}\")\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = 'NA'\n",
    "\n",
    "\n",
    "async def process_images_for_shots(number_of_shots, all_data_results):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for i in range(len(all_data)):#range(0, min(samples_to_run, len(all_data))):\n",
    "            task = asyncio.ensure_future(process_image(session, i, number_of_shots, all_data_results))\n",
    "            tasks.append(task)\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "async def main():\n",
    "    all_data_results = all_data.copy(deep=True)\n",
    "    all_data_results.columns = all_data_results.columns.map(str)\n",
    "\n",
    "    for number_of_shots in [0]:#, 1, 2, 4, 8]:\n",
    "        await process_images_for_shots(number_of_shots, all_data_results)\n",
    "    all_data_results.to_csv(\"01-Fruit.csv\")\n",
    "    # print(all_data_results.iloc[9:16])\n",
    "    print(\"done\")\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_results= pd.read_csv(\"01-Fruit-high-setting.csv\")\n",
    "all_data_results.head()\n",
    "#calculate wrong predictions\n",
    "wrong_predictions = all_data_results[all_data_results['1'] != all_data_results['# of Shots 0']]\n",
    "print(f\"Number of wrong predictions: {len(wrong_predictions)}\")\n",
    "#now printing the samples which are predicted wrong\n",
    "wrong_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os;os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. drowsy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import time\n",
    "\n",
    "nest_asyncio.apply()\n",
    "global all_data_results\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Set the base directory\n",
    "base_directory = 'data/Drowsy_datset/train'\n",
    "\n",
    "# FOR API\n",
    "max_requests_per_half_minute = 20\n",
    "num_instances_per_class = 50\n",
    "\n",
    "# Define the list of expected class labels\n",
    "expected_classes = ['DROWSY', 'NATURAL']\n",
    "\n",
    "# Create empty lists to store file paths and labels\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "# Loop through all subdirectories in the base directory\n",
    "for subdir in os.listdir(base_directory):\n",
    "    if subdir in expected_classes:\n",
    "        subdir_path = os.path.join(base_directory, subdir)\n",
    "        # Loop through all files in the subdirectory\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "                # Append the file path and label to the respective lists\n",
    "                file_paths.append(os.path.join(subdir_path, filename))\n",
    "                labels.append(subdir)\n",
    "\n",
    "# Create a dataframe from the lists\n",
    "data = pd.DataFrame({0: file_paths, 1: labels})\n",
    "\n",
    "# Get the unique classes\n",
    "unique_classes = data[1].unique()\n",
    "\n",
    "# Create a new dataframe with sampled data\n",
    "sampled_data = pd.DataFrame(columns=[0, 1])\n",
    "\n",
    "# Sample uniformly from each class\n",
    "for cls in unique_classes:\n",
    "    class_data = data[data[1] == cls].sample(n=num_instances_per_class, random_state=42)\n",
    "    sampled_data = pd.concat([sampled_data, class_data], ignore_index=True)\n",
    "\n",
    "# Shuffle the sampled data\n",
    "all_data = shuffle(sampled_data, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "def load_image(image_path: str) -> str:\n",
    "    \"\"\"Load image from file and encode it as base64.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model =\"gpt-4o-2024-05-13\" #\"gpt-4-turbo\"\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "vision_prompt = f\"\"\"\n",
    "Given the image, identify the class. Use the following list of possible classes for your prediction It should be one of the : {expected_classes}. Be attentive to subtle details as some classes may appear similar. Provide your answer in the following JSON format:\n",
    "{{\"prediction\": \"class_name\"}}\n",
    "Replace \"class_name\" with the appropriate class from the list above based on your analysis of the image.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "request_times = []\n",
    "\n",
    "async def get_image_informations(session, inputs: dict) -> dict:\n",
    "    \"\"\"Invoke model with image and prompt.\"\"\"\n",
    "    global request_times\n",
    "    \n",
    "    while True:\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Remove old request times outside the current time window\n",
    "        while request_times and request_times[0] <= current_time - 30:\n",
    "            request_times.pop(0)\n",
    "        \n",
    "        if len(request_times) < max_requests_per_half_minute:\n",
    "            request_times.append(current_time)\n",
    "            break\n",
    "        else:\n",
    "            # If the rate limit is exceeded, wait for a short duration before checking again\n",
    "            await asyncio.sleep(1)\n",
    "    \n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"response_format\":{ \"type\": \"json_object\" },\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": vision_prompt},\n",
    "                    *inputs['examples'],\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{inputs['image']}\",\n",
    "                            \"detail\": \"high\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "    async with session.post(url, headers=headers, json=payload) as response:\n",
    "        result = await response.json()\n",
    "        print(result)\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            return result\n",
    "        else:\n",
    "            raise Exception(\"Unexpected API response format\")\n",
    "\n",
    "async def process_image(session, i, number_of_shots, all_data_results):\n",
    "    try:\n",
    "        image_path = all_data[0][i]\n",
    "        image_base64 = load_image(image_path)\n",
    "        examples = []\n",
    "\n",
    "        # Get the number of rows in all_data\n",
    "        num_rows = len(all_data)\n",
    "\n",
    "        # Select random indices from the dataframe\n",
    "        random_indices = random.sample(range(num_rows), number_of_shots)\n",
    "\n",
    "        for j in random_indices:\n",
    "            example_image_path = all_data[0][j]\n",
    "            example_image_base64 = load_image(example_image_path)\n",
    "            examples.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{example_image_base64}\", \"detail\": \"high\"}})\n",
    "            examples.append({\"type\": \"text\", \"text\": f'{{\"prediction\": \"{all_data.at[j, 1]}\"}}' })\n",
    "\n",
    "\n",
    "        result = await get_image_informations(session, {\"image\": image_base64, \"examples\": examples})\n",
    "        prediction = result[\"choices\"][0]['message']['content']\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = json.loads(prediction)['prediction']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {all_data[0][i]}: {str(e)}\")\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = 'NA'\n",
    "\n",
    "\n",
    "async def process_images_for_shots(number_of_shots, all_data_results):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for i in range(len(all_data)):#range(0, min(samples_to_run, len(all_data))):\n",
    "            task = asyncio.ensure_future(process_image(session, i, number_of_shots, all_data_results))\n",
    "            tasks.append(task)\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "async def main():\n",
    "    all_data_results = all_data.copy(deep=True)\n",
    "    all_data_results.columns = all_data_results.columns.map(str)\n",
    "\n",
    "    for number_of_shots in [0]:#, 1, 2, 4, 8]:\n",
    "        await process_images_for_shots(number_of_shots, all_data_results)\n",
    "    all_data_results.to_csv(\"02-Drowsy.csv\")\n",
    "    # print(all_data_results.iloc[9:16])\n",
    "    print(\"done\")\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. crop disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import time\n",
    "\n",
    "nest_asyncio.apply()\n",
    "global all_data_results\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Set the base directory\n",
    "base_directory = 'data/crop-disease'\n",
    "\n",
    "# FOR API\n",
    "max_requests_per_half_minute = 20\n",
    "\n",
    "total_samples_to_check=100\n",
    "# Define the list of expected class labels\n",
    "expected_classes = ['Clubroot', 'Canker', 'Anthracnose', 'Blossom End Rot',\n",
    "       'Verticillium', 'Powdery Mildew', 'Leaf Spots', 'Mosaic Virus',\n",
    "       'Botrytis', 'Fire Blight', 'Cedar Apple Rust', 'Gray Mold',\n",
    "       'Fusarium', 'Nematodes', 'Apple Scab', 'Crown Gall', 'Black Spot',\n",
    "       'Downy Mildew', 'Blight', 'Brown Rot']\n",
    "\n",
    "num_instances_per_class = int(total_samples_to_check/len(expected_classes))\n",
    "# Create empty lists to store file paths and labels\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "# Loop through all subdirectories in the base directory\n",
    "for subdir in os.listdir(base_directory):\n",
    "    if subdir==\".DS_Store\":\n",
    "        continue\n",
    "    # if subdir in expected_classes:\n",
    "    subdir_path = os.path.join(base_directory, subdir)\n",
    "    # Loop through all files in the subdirectory\n",
    "    for filename in os.listdir(subdir_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            # Append the file path and label to the respective lists\n",
    "            file_paths.append(os.path.join(subdir_path, filename))\n",
    "            labels.append(subdir)\n",
    "\n",
    "# Create a dataframe from the lists\n",
    "data = pd.DataFrame({0: file_paths, 1: labels})\n",
    "\n",
    "# Get the unique classes\n",
    "unique_classes = data[1].unique()\n",
    "\n",
    "# Create a new dataframe with sampled data\n",
    "sampled_data = pd.DataFrame(columns=[0, 1])\n",
    "\n",
    "# Sample uniformly from each class\n",
    "for cls in unique_classes:\n",
    "    class_data = data[data[1] == cls].sample(n=num_instances_per_class, random_state=42)\n",
    "    sampled_data = pd.concat([sampled_data, class_data], ignore_index=True)\n",
    "\n",
    "# Shuffle the sampled data\n",
    "all_data = shuffle(sampled_data, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "def load_image(image_path: str) -> str:\n",
    "    \"\"\"Load image from file and encode it as base64.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model =\"gpt-4o-2024-05-13\" #\"gpt-4-turbo\"\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "vision_prompt = f\"\"\"\n",
    "Given the image, identify the class. Use the following list of possible classes for your prediction It should be one of the : {expected_classes}. Be attentive to subtle details as some classes may appear similar. Provide your answer in the following JSON format:\n",
    "{{\"prediction\": \"class_name\"}}\n",
    "Replace \"class_name\" with the appropriate class from the list above based on your analysis of the image.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "request_times = []\n",
    "\n",
    "async def get_image_informations(session, inputs: dict) -> dict:\n",
    "    \"\"\"Invoke model with image and prompt.\"\"\"\n",
    "    global request_times\n",
    "    \n",
    "    while True:\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Remove old request times outside the current time window\n",
    "        while request_times and request_times[0] <= current_time - 30:\n",
    "            request_times.pop(0)\n",
    "        \n",
    "        if len(request_times) < max_requests_per_half_minute:\n",
    "            request_times.append(current_time)\n",
    "            break\n",
    "        else:\n",
    "            # If the rate limit is exceeded, wait for a short duration before checking again\n",
    "            await asyncio.sleep(1)\n",
    "    \n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"response_format\":{ \"type\": \"json_object\" },\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": vision_prompt},\n",
    "                    *inputs['examples'],\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{inputs['image']}\",\n",
    "                            \"detail\": \"high\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "    async with session.post(url, headers=headers, json=payload) as response:\n",
    "        result = await response.json()\n",
    "        print(result)\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            return result\n",
    "        else:\n",
    "            raise Exception(\"Unexpected API response format\")\n",
    "\n",
    "async def process_image(session, i, number_of_shots, all_data_results):\n",
    "    try:\n",
    "        image_path = all_data[0][i]\n",
    "        image_base64 = load_image(image_path)\n",
    "        examples = []\n",
    "\n",
    "        # Get the number of rows in all_data\n",
    "        num_rows = len(all_data)\n",
    "\n",
    "        # Select random indices from the dataframe\n",
    "        random_indices = random.sample(range(num_rows), number_of_shots)\n",
    "\n",
    "        for j in random_indices:\n",
    "            example_image_path = all_data[0][j]\n",
    "            example_image_base64 = load_image(example_image_path)\n",
    "            examples.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{example_image_base64}\", \"detail\": \"high\"}})\n",
    "            examples.append({\"type\": \"text\", \"text\": f'{{\"prediction\": \"{all_data.at[j, 1]}\"}}' })\n",
    "\n",
    "\n",
    "        result = await get_image_informations(session, {\"image\": image_base64, \"examples\": examples})\n",
    "        prediction = result[\"choices\"][0]['message']['content']\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = json.loads(prediction)['prediction']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {all_data[0][i]}: {str(e)}\")\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = 'NA'\n",
    "\n",
    "\n",
    "async def process_images_for_shots(number_of_shots, all_data_results):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for i in range(len(all_data)):#range(0, min(samples_to_run, len(all_data))):\n",
    "            task = asyncio.ensure_future(process_image(session, i, number_of_shots, all_data_results))\n",
    "            tasks.append(task)\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "async def main():\n",
    "    all_data_results = all_data.copy(deep=True)\n",
    "    all_data_results.columns = all_data_results.columns.map(str)\n",
    "\n",
    "    for number_of_shots in [0]:#, 1, 2, 4, 8]:\n",
    "        await process_images_for_shots(number_of_shots, all_data_results)\n",
    "    all_data_results.to_csv(\"03-Crop.csv\")\n",
    "    # print(all_data_results.iloc[9:16])\n",
    "    print(\"done\")\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. glaucoma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import time\n",
    "\n",
    "nest_asyncio.apply()\n",
    "global all_data_results\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Set the base directory\n",
    "base_directory = 'DIRECTORY/data/glaucoma-dataset/Dataset_New/Dataset_New/ACRIMA'\n",
    "\n",
    "# FOR API\n",
    "max_requests_per_half_minute = 20\n",
    "\n",
    "total_samples_to_check=100\n",
    "# Define the list of expected class labels\n",
    "expected_classes = ['glaucoma', 'normal']\n",
    "\n",
    "num_instances_per_class = int(total_samples_to_check/len(expected_classes))\n",
    "# Create empty lists to store file paths and labels\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "# Loop through all subdirectories in the base directory\n",
    "for subdir in os.listdir(base_directory):\n",
    "    if subdir==\".DS_Store\":\n",
    "        continue\n",
    "    # if subdir in expected_classes:\n",
    "    subdir_path = os.path.join(base_directory, subdir)\n",
    "    # Loop through all files in the subdirectory\n",
    "    for filename in os.listdir(subdir_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            # Append the file path and label to the respective lists\n",
    "            file_paths.append(os.path.join(subdir_path, filename))\n",
    "            labels.append(subdir)\n",
    "\n",
    "# Create a dataframe from the lists\n",
    "data = pd.DataFrame({0: file_paths, 1: labels})\n",
    "\n",
    "# Get the unique classes\n",
    "unique_classes = data[1].unique()\n",
    "\n",
    "# Create a new dataframe with sampled data\n",
    "sampled_data = pd.DataFrame(columns=[0, 1])\n",
    "\n",
    "# Sample uniformly from each class\n",
    "for cls in unique_classes:\n",
    "    class_data = data[data[1] == cls].sample(n=num_instances_per_class, random_state=42)\n",
    "    sampled_data = pd.concat([sampled_data, class_data], ignore_index=True)\n",
    "\n",
    "# Shuffle the sampled data\n",
    "all_data = shuffle(sampled_data, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "def load_image(image_path: str) -> str:\n",
    "    \"\"\"Load image from file and encode it as base64.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model =\"gpt-4o-2024-05-13\" #\"gpt-4-turbo\"\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "vision_prompt = f\"\"\"\n",
    "Given the image, identify the class. Use the following list of possible classes for your prediction It should be one of the : {expected_classes}. Be attentive to subtle details as some classes may appear similar. Provide your answer in the following JSON format:\n",
    "{{\"prediction\": \"class_name\"}}\n",
    "Replace \"class_name\" with the appropriate class from the list above based on your analysis of the image.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "request_times = []\n",
    "\n",
    "async def get_image_informations(session, inputs: dict) -> dict:\n",
    "    \"\"\"Invoke model with image and prompt.\"\"\"\n",
    "    global request_times\n",
    "    \n",
    "    while True:\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Remove old request times outside the current time window\n",
    "        while request_times and request_times[0] <= current_time - 30:\n",
    "            request_times.pop(0)\n",
    "        \n",
    "        if len(request_times) < max_requests_per_half_minute:\n",
    "            request_times.append(current_time)\n",
    "            break\n",
    "        else:\n",
    "            # If the rate limit is exceeded, wait for a short duration before checking again\n",
    "            await asyncio.sleep(1)\n",
    "    \n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"response_format\":{ \"type\": \"json_object\" },\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": vision_prompt},\n",
    "                    *inputs['examples'],\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{inputs['image']}\",\n",
    "                            \"detail\": \"high\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "    async with session.post(url, headers=headers, json=payload) as response:\n",
    "        result = await response.json()\n",
    "        print(result)\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            return result\n",
    "        else:\n",
    "            raise Exception(\"Unexpected API response format\")\n",
    "\n",
    "async def process_image(session, i, number_of_shots, all_data_results):\n",
    "    try:\n",
    "        image_path = all_data[0][i]\n",
    "        image_base64 = load_image(image_path)\n",
    "        examples = []\n",
    "\n",
    "        # Get the number of rows in all_data\n",
    "        num_rows = len(all_data)\n",
    "\n",
    "        # Select random indices from the dataframe\n",
    "        random_indices = random.sample(range(num_rows), number_of_shots)\n",
    "\n",
    "        for j in random_indices:\n",
    "            example_image_path = all_data[0][j]\n",
    "            example_image_base64 = load_image(example_image_path)\n",
    "            examples.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{example_image_base64}\", \"detail\": \"high\"}})\n",
    "            examples.append({\"type\": \"text\", \"text\": f'{{\"prediction\": \"{all_data.at[j, 1]}\"}}' })\n",
    "\n",
    "\n",
    "        result = await get_image_informations(session, {\"image\": image_base64, \"examples\": examples})\n",
    "        prediction = result[\"choices\"][0]['message']['content']\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = json.loads(prediction)['prediction']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {all_data[0][i]}: {str(e)}\")\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = 'NA'\n",
    "\n",
    "\n",
    "async def process_images_for_shots(number_of_shots, all_data_results):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for i in range(len(all_data)):#range(0, min(samples_to_run, len(all_data))):\n",
    "            task = asyncio.ensure_future(process_image(session, i, number_of_shots, all_data_results))\n",
    "            tasks.append(task)\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "async def main():\n",
    "    all_data_results = all_data.copy(deep=True)\n",
    "    all_data_results.columns = all_data_results.columns.map(str)\n",
    "\n",
    "    for number_of_shots in [0,1, 2, 4]:#, 1, 2, 4, 8]:\n",
    "        await process_images_for_shots(number_of_shots, all_data_results)\n",
    "    all_data_results.to_csv(\"04-Glaucoma.csv\")\n",
    "    # print(all_data_results.iloc[9:16])\n",
    "    print(\"done\")\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. CT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import time\n",
    "\n",
    "nest_asyncio.apply()\n",
    "global all_data_results\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Set the base directory\n",
    "base_directory = 'DIRECTORY/data/computed-tomography-ct-of-the-brain/files'\n",
    "\n",
    "# FOR API\n",
    "max_requests_per_half_minute = 20\n",
    "\n",
    "total_samples_to_check=100\n",
    "# Define the list of expected class labels\n",
    "expected_classes = ['aneurysm', 'cancer', 'tumor']\n",
    "\n",
    "num_instances_per_class = int(total_samples_to_check/len(expected_classes))\n",
    "# Create empty lists to store file paths and labels\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "# Loop through all subdirectories in the base directory\n",
    "for subdir in os.listdir(base_directory):\n",
    "    if subdir==\".DS_Store\":\n",
    "        continue\n",
    "    # if subdir in expected_classes:\n",
    "    subdir_path = os.path.join(base_directory, subdir)\n",
    "    # Loop through all files in the subdirectory\n",
    "    for filename in os.listdir(subdir_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            # Append the file path and label to the respective lists\n",
    "            file_paths.append(os.path.join(subdir_path, filename))\n",
    "            labels.append(subdir)\n",
    "\n",
    "# Create a dataframe from the lists\n",
    "data = pd.DataFrame({0: file_paths, 1: labels})\n",
    "\n",
    "# Get the unique classes\n",
    "unique_classes = data[1].unique()\n",
    "\n",
    "# Create a new dataframe with sampled data\n",
    "sampled_data = pd.DataFrame(columns=[0, 1])\n",
    "\n",
    "# Sample uniformly from each class\n",
    "for cls in unique_classes:\n",
    "    class_data = data[data[1] == cls].sample(n=num_instances_per_class, random_state=42)\n",
    "    sampled_data = pd.concat([sampled_data, class_data], ignore_index=True)\n",
    "\n",
    "# Shuffle the sampled data\n",
    "all_data = shuffle(sampled_data, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "def load_image(image_path: str) -> str:\n",
    "    \"\"\"Load image from file and encode it as base64.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model =\"gpt-4o-2024-05-13\" #\"gpt-4-turbo\"\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "vision_prompt = f\"\"\"\n",
    "Given the image, identify the class. Use the following list of possible classes for your prediction It should be one of the : {expected_classes}. Be attentive to subtle details as some classes may appear similar. Provide your answer in the following JSON format:\n",
    "{{\"prediction\": \"class_name\"}}\n",
    "Replace \"class_name\" with the appropriate class from the list above based on your analysis of the image.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "request_times = []\n",
    "\n",
    "async def get_image_informations(session, inputs: dict) -> dict:\n",
    "    \"\"\"Invoke model with image and prompt.\"\"\"\n",
    "    global request_times\n",
    "    \n",
    "    while True:\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Remove old request times outside the current time window\n",
    "        while request_times and request_times[0] <= current_time - 30:\n",
    "            request_times.pop(0)\n",
    "        \n",
    "        if len(request_times) < max_requests_per_half_minute:\n",
    "            request_times.append(current_time)\n",
    "            break\n",
    "        else:\n",
    "            # If the rate limit is exceeded, wait for a short duration before checking again\n",
    "            await asyncio.sleep(1)\n",
    "    \n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"response_format\":{ \"type\": \"json_object\" },\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": vision_prompt},\n",
    "                    *inputs['examples'],\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{inputs['image']}\",\n",
    "                            \"detail\": \"high\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "    async with session.post(url, headers=headers, json=payload) as response:\n",
    "        result = await response.json()\n",
    "        print(result)\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            return result\n",
    "        else:\n",
    "            raise Exception(\"Unexpected API response format\")\n",
    "\n",
    "async def process_image(session, i, number_of_shots, all_data_results):\n",
    "    try:\n",
    "        image_path = all_data[0][i]\n",
    "        image_base64 = load_image(image_path)\n",
    "        examples = []\n",
    "\n",
    "        # Get the number of rows in all_data\n",
    "        num_rows = len(all_data)\n",
    "\n",
    "        # Select random indices from the dataframe\n",
    "        random_indices = random.sample(range(num_rows), number_of_shots)\n",
    "\n",
    "        for j in random_indices:\n",
    "            example_image_path = all_data[0][j]\n",
    "            example_image_base64 = load_image(example_image_path)\n",
    "            examples.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{example_image_base64}\", \"detail\": \"high\"}})\n",
    "            examples.append({\"type\": \"text\", \"text\": f'{{\"prediction\": \"{all_data.at[j, 1]}\"}}' })\n",
    "\n",
    "\n",
    "        result = await get_image_informations(session, {\"image\": image_base64, \"examples\": examples})\n",
    "        prediction = result[\"choices\"][0]['message']['content']\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = json.loads(prediction)['prediction']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {all_data[0][i]}: {str(e)}\")\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = 'NA'\n",
    "\n",
    "\n",
    "async def process_images_for_shots(number_of_shots, all_data_results):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for i in range(len(all_data)):#range(0, min(samples_to_run, len(all_data))):\n",
    "            task = asyncio.ensure_future(process_image(session, i, number_of_shots, all_data_results))\n",
    "            tasks.append(task)\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "async def main():\n",
    "    all_data_results = all_data.copy(deep=True)\n",
    "    all_data_results.columns = all_data_results.columns.map(str)\n",
    "\n",
    "    for number_of_shots in [0]:#, 1, 2, 4, 8]:\n",
    "        await process_images_for_shots(number_of_shots, all_data_results)\n",
    "    all_data_results.to_csv(\"05-CT.csv\")\n",
    "    # print(all_data_results.iloc[9:16])\n",
    "    print(\"done\")\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import time\n",
    "\n",
    "nest_asyncio.apply()\n",
    "global all_data_results\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Set the base directory for images\n",
    "base_directory_images = 'DIRECTORY/data/flickr-image-caption/images'\n",
    "\n",
    "# Set the path for the captions file\n",
    "captions_file = 'DIRECTORY/data/flickr-image-caption/captions.txt'\n",
    "\n",
    "# FOR API\n",
    "max_requests_per_half_minute = 20\n",
    "total_samples_to_check = 100\n",
    "\n",
    "# Read the captions file\n",
    "captions_df = pd.read_csv(captions_file)\n",
    "\n",
    "# Sample the required number of rows\n",
    "sampled_captions = captions_df.sample(n=total_samples_to_check, random_state=42)\n",
    "\n",
    "# Create empty lists to store file paths and captions\n",
    "file_paths = []\n",
    "captions = []\n",
    "\n",
    "# Iterate over the sampled rows\n",
    "for index, row in sampled_captions.iterrows():\n",
    "    image_file = row['image']\n",
    "    image_caption = row['caption']\n",
    "    \n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(base_directory_images, image_file)\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(file_path):\n",
    "        file_paths.append(file_path)\n",
    "        captions.append(image_caption)\n",
    "\n",
    "# Create a dataframe from the lists\n",
    "data = pd.DataFrame({0: file_paths, 1: captions})\n",
    "\n",
    "# Shuffle the data\n",
    "all_data = shuffle(data, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def load_image(image_path: str) -> str:\n",
    "    \"\"\"Load image from file and encode it as base64.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model =\"gpt-4o-2024-05-13\" #\"gpt-4-turbo\"\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "# vision_prompt = f\"\"\"\n",
    "# Given the image, identify the class of the fruit presented. Use the following list of possible classes for your prediction It should be one of the : {expected_classes}. Be attentive to subtle details as some classes may appear similar. Provide your answer in the following JSON format:\n",
    "# {{\"prediction\": \"class_name\"}}\n",
    "# Replace \"class_name\" with the appropriate class from the list above based on your analysis of the image.\n",
    "# \"\"\"\n",
    "vision_prompt = f\"\"\"\n",
    "Given the image, write a short caption for it in a very short single line. Provide your answer in the following JSON format:\n",
    "{{\"prediction\": \"caption .\"}}\n",
    "Replace \"caption\" with the appropriate caption based on your analysis of the image. and see i put a full stop (.) at the end of the caption after a space. \n",
    "\"\"\"\n",
    "\n",
    "request_times = []\n",
    "\n",
    "async def get_image_informations(session, inputs: dict) -> dict:\n",
    "    \"\"\"Invoke model with image and prompt.\"\"\"\n",
    "    global request_times\n",
    "    \n",
    "    while True:\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Remove old request times outside the current time window\n",
    "        while request_times and request_times[0] <= current_time - 30:\n",
    "            request_times.pop(0)\n",
    "        \n",
    "        if len(request_times) < max_requests_per_half_minute:\n",
    "            request_times.append(current_time)\n",
    "            break\n",
    "        else:\n",
    "            # If the rate limit is exceeded, wait for a short duration before checking again\n",
    "            await asyncio.sleep(1)\n",
    "    \n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"response_format\":{ \"type\": \"json_object\" },\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": vision_prompt},\n",
    "                    *inputs['examples'],\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{inputs['image']}\",\n",
    "                            \"detail\": \"high\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "    async with session.post(url, headers=headers, json=payload) as response:\n",
    "        result = await response.json()\n",
    "        print(result)\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            return result\n",
    "        else:\n",
    "            raise Exception(\"Unexpected API response format\")\n",
    "\n",
    "async def process_image(session, i, number_of_shots, all_data_results):\n",
    "    try:\n",
    "        image_path = all_data[0][i]\n",
    "        image_base64 = load_image(image_path)\n",
    "        examples = []\n",
    "\n",
    "        # Get the number of rows in all_data\n",
    "        num_rows = len(all_data)\n",
    "\n",
    "        # Select random indices from the dataframe\n",
    "        random_indices = random.sample(range(num_rows), number_of_shots)\n",
    "\n",
    "        for j in random_indices:\n",
    "            example_image_path = all_data[0][j]\n",
    "            example_image_base64 = load_image(example_image_path)\n",
    "            examples.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{example_image_base64}\", \"detail\": \"high\"}})\n",
    "            examples.append({\"type\": \"text\", \"text\": f'{{\"prediction\": \"{all_data.at[j, 1]}\"}}' })\n",
    "\n",
    "\n",
    "        result = await get_image_informations(session, {\"image\": image_base64, \"examples\": examples})\n",
    "        prediction = result[\"choices\"][0]['message']['content']\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = json.loads(prediction)['prediction']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {all_data[0][i]}: {str(e)}\")\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = 'NA'\n",
    "\n",
    "\n",
    "async def process_images_for_shots(number_of_shots, all_data_results):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for i in range(len(all_data)):#range(0, min(samples_to_run, len(all_data))):\n",
    "            task = asyncio.ensure_future(process_image(session, i, number_of_shots, all_data_results))\n",
    "            tasks.append(task)\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "async def main():\n",
    "    all_data_results = all_data.copy(deep=True)\n",
    "    all_data_results.columns = all_data_results.columns.map(str)\n",
    "\n",
    "    for number_of_shots in [0]:#, 1, 2, 4]:#, 1, 2, 4, 8]:\n",
    "        await process_images_for_shots(number_of_shots, all_data_results)\n",
    "    all_data_results.to_csv(\"06-Captions.csv\")\n",
    "    # print(all_data_results.iloc[9:16])\n",
    "    print(\"done\")\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. vqa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import time\n",
    "import random\n",
    "\n",
    "nest_asyncio.apply()\n",
    "global all_data_results\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Set the base directory for images\n",
    "base_directory = 'DIRECTORY/data/VQA'\n",
    "images_directory = os.path.join(base_directory, 'images')\n",
    "\n",
    "# Set the path for the data file\n",
    "data_file = os.path.join(base_directory, 'data.csv')\n",
    "\n",
    "# Read the list of possible answers from the answer_space.txt file\n",
    "with open(os.path.join(base_directory, 'answer_space.txt'), 'r') as f:\n",
    "    answer_space = f.read().splitlines()\n",
    "\n",
    "# FOR API\n",
    "max_requests_per_half_minute = 20\n",
    "total_samples_to_check = 100\n",
    "\n",
    "# Read the data file\n",
    "data_df = pd.read_csv(data_file)\n",
    "\n",
    "# Sample the required number of rows\n",
    "sampled_data = data_df.sample(n=total_samples_to_check, random_state=42)\n",
    "# the answers are comma seperated\n",
    "sampled_data['answer'] = sampled_data['answer'].apply(lambda x: x.split(',')[0])\n",
    "\n",
    "# Create a dataframe from the sampled data\n",
    "data = pd.DataFrame({'file_path': [os.path.join(images_directory, f\"{row['image_id']}.png\") for _, row in sampled_data.iterrows()],\n",
    "                     'question': sampled_data['question'],\n",
    "                     'answer': sampled_data['answer']})\n",
    "\n",
    "# Shuffle the data\n",
    "all_data = shuffle(data, random_state=42).reset_index(drop=True)\n",
    "\n",
    "def load_image(image_path: str) -> str:\n",
    "    \"\"\"Load image from file and encode it as base64.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model =\"gpt-4o-2024-05-13\" #\"gpt-4-turbo\"\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "vision_prompt = f\"\"\"\n",
    "Given the image and question, provide the appropriate answer from the following list of possible answers:\n",
    "{answer_space}\n",
    "\n",
    "Provide your answer in the following JSON format:\n",
    "prediction: \"<answer>\"\n",
    "Replace \"<answer>\" with the appropriate answer from the list above based on your analysis of the image and question. The question is: {{question}}\n",
    "\"\"\"\n",
    "\n",
    "request_times = []\n",
    "\n",
    "async def get_image_informations(session, inputs: dict) -> dict:\n",
    "    \"\"\"Invoke model with image and prompt.\"\"\"\n",
    "    global request_times\n",
    "    \n",
    "    while True:\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Remove old request times outside the current time window\n",
    "        while request_times and request_times[0] <= current_time - 30:\n",
    "            request_times.pop(0)\n",
    "        \n",
    "        if len(request_times) < max_requests_per_half_minute:\n",
    "            request_times.append(current_time)\n",
    "            break\n",
    "        else:\n",
    "            # If the rate limit is exceeded, wait for a short duration before checking again\n",
    "            await asyncio.sleep(1)\n",
    "    \n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"response_format\":{ \"type\": \"json_object\" },\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    *inputs['examples'],\n",
    "                    {\"type\": \"text\", \"text\": vision_prompt.format(question=inputs['question'])},\n",
    "\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{inputs['image']}\",\n",
    "                            \"detail\": \"high\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "    async with session.post(url, headers=headers, json=payload) as response:\n",
    "        result = await response.json()\n",
    "        print(result)\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            return result\n",
    "        else:\n",
    "            raise Exception(\"Unexpected API response format\")\n",
    "\n",
    "async def process_image(session, i, number_of_shots, all_data_results):\n",
    "    try:\n",
    "        image_path = all_data['file_path'][i]\n",
    "        question = all_data['question'][i]\n",
    "        image_base64 = load_image(image_path)\n",
    "        examples = []\n",
    "\n",
    "        # Get the number of rows in all_data\n",
    "        num_rows = len(all_data)\n",
    "\n",
    "        # Select random indices from the dataframe\n",
    "        # random_indices = random.sample(range(num_rows), number_of_shots)\n",
    "        random_indices = random.sample([idx for idx in range(num_rows) if idx != i], number_of_shots)\n",
    "\n",
    "        for j in random_indices:\n",
    "            example_image_path = all_data['file_path'][j]\n",
    "            example_image_base64 = load_image(example_image_path)\n",
    "            example_question = all_data['question'][j]\n",
    "            examples.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{example_image_base64}\", \"detail\": \"high\"}})\n",
    "            examples.append({\"type\": \"text\", \"text\": f\"Question: {example_question}\"})\n",
    "            examples.append({\"type\": \"text\", \"text\": f'{{\"prediction\": \"{all_data.at[j, \"answer\"]}\"}}' })\n",
    "\n",
    "\n",
    "        result = await get_image_informations(session, {\"image\": image_base64, \"question\": question, \"examples\": examples})\n",
    "        prediction = result[\"choices\"][0]['message']['content']\n",
    "        prediction_dict = json.loads(prediction)\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = prediction_dict['prediction']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {all_data['file_path'][i]}: {str(e)}\")\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = 'NA'\n",
    "\n",
    "\n",
    "async def process_images_for_shots(number_of_shots, all_data_results):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for i in range(len(all_data)):#range(0, min(samples_to_run, len(all_data))):\n",
    "            task = asyncio.ensure_future(process_image(session, i, number_of_shots, all_data_results))\n",
    "            tasks.append(task)\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "async def main():\n",
    "    all_data_results = all_data.copy(deep=True)\n",
    "    all_data_results.columns = all_data_results.columns.map(str)\n",
    "\n",
    "    for number_of_shots in [0, 1, 2, 4, 8]:#, 1, 2, 4]:#, 1, 2, 4, 8]:\n",
    "        await process_images_for_shots(number_of_shots, all_data_results)\n",
    "    all_data_results.to_csv(\"07-VQA.csv\")\n",
    "    # print(all_data_results.iloc[9:16])\n",
    "    print(\"done\")\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Set the base directory for images\n",
    "base_directory = 'DIRECTORY/data/VQA'\n",
    "\n",
    "# Set the path for the data file\n",
    "data_file = os.path.join(base_directory, 'data.csv')\n",
    "data_df = pd.read_csv(data_file)\n",
    "\n",
    "file_read = pd.read_csv(\"07-VQA-all.csv\")\n",
    "\n",
    "# Merge the data_df with file_read based on the index\n",
    "merged_df = file_read.merge(data_df[['question', 'answer']], left_index=True, right_index=True)\n",
    "\n",
    "# Rename the 'answer' column to 'ground_truth'\n",
    "merged_df = merged_df.rename(columns={'answer': 'ground_truth'})\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "merged_df.to_csv(\"07-VQA-all-with-ground-truth.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Soybean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import time\n",
    "\n",
    "nest_asyncio.apply()\n",
    "global all_data_results\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Set the base directory\n",
    "base_directory = 'data/Soybean Seeds'\n",
    "\n",
    "# FOR API\n",
    "max_requests_per_half_minute = 100\n",
    "\n",
    "total_samples_to_check=100\n",
    "# Define the list of expected class labels\n",
    "expected_classes = ['Broken', 'Immature soybeans','Intact','Skin-damaged' ,'Spotted' ]\n",
    "\n",
    "num_instances_per_class = int(total_samples_to_check/len(expected_classes))\n",
    "# Create empty lists to store file paths and labels\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "# Loop through all subdirectories in the base directory\n",
    "for subdir in os.listdir(base_directory):\n",
    "    if subdir==\".DS_Store\":\n",
    "        continue\n",
    "    # if subdir in expected_classes:\n",
    "    subdir_path = os.path.join(base_directory, subdir)\n",
    "    # Loop through all files in the subdirectory\n",
    "    for filename in os.listdir(subdir_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            # Append the file path and label to the respective lists\n",
    "            file_paths.append(os.path.join(subdir_path, filename))\n",
    "            labels.append(subdir)\n",
    "\n",
    "# Create a dataframe from the lists\n",
    "data = pd.DataFrame({0: file_paths, 1: labels})\n",
    "\n",
    "# Get the unique classes\n",
    "unique_classes = data[1].unique()\n",
    "\n",
    "# Create a new dataframe with sampled data\n",
    "sampled_data = pd.DataFrame(columns=[0, 1])\n",
    "\n",
    "# Sample uniformly from each class\n",
    "for cls in unique_classes:\n",
    "    class_data = data[data[1] == cls].sample(n=num_instances_per_class, random_state=42)\n",
    "    sampled_data = pd.concat([sampled_data, class_data], ignore_index=True)\n",
    "\n",
    "# Shuffle the sampled data\n",
    "all_data = shuffle(sampled_data, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "def load_image(image_path: str) -> str:\n",
    "    \"\"\"Load image from file and encode it as base64.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model =\"gpt-4o-2024-05-13\" #\"gpt-4-turbo\"\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "vision_prompt = f\"\"\"\n",
    "Given the image, identify the class. Use the following list of possible classes for your prediction It should be one of the : {expected_classes}. Be attentive to subtle details as some classes may appear similar. Provide your answer in the following JSON format:\n",
    "{{\"prediction\": \"class_name\"}}\n",
    "Replace \"class_name\" with the appropriate class from the list above based on your analysis of the image.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "request_times = []\n",
    "\n",
    "async def get_image_informations(session, inputs: dict) -> dict:\n",
    "    \"\"\"Invoke model with image and prompt.\"\"\"\n",
    "    global request_times\n",
    "    \n",
    "    while True:\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Remove old request times outside the current time window\n",
    "        while request_times and request_times[0] <= current_time - 30:\n",
    "            request_times.pop(0)\n",
    "        \n",
    "        if len(request_times) < max_requests_per_half_minute:\n",
    "            request_times.append(current_time)\n",
    "            break\n",
    "        else:\n",
    "            # If the rate limit is exceeded, wait for a short duration before checking again\n",
    "            await asyncio.sleep(1)\n",
    "    \n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"response_format\":{ \"type\": \"json_object\" },\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": vision_prompt},\n",
    "                    *inputs['examples'],\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{inputs['image']}\",\n",
    "                            \"detail\": \"high\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "    async with session.post(url, headers=headers, json=payload) as response:\n",
    "        result = await response.json()\n",
    "        print(result)\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            return result\n",
    "        else:\n",
    "            raise Exception(\"Unexpected API response format\")\n",
    "\n",
    "async def process_image(session, i, number_of_shots, all_data_results):\n",
    "    try:\n",
    "        image_path = all_data[0][i]\n",
    "        image_base64 = load_image(image_path)\n",
    "        examples = []\n",
    "\n",
    "        # Get the number of rows in all_data\n",
    "        num_rows = len(all_data)\n",
    "\n",
    "        # Select random indices from the dataframe\n",
    "        random_indices = random.sample([idx for idx in range(num_rows) if idx != i], number_of_shots)\n",
    "\n",
    "        for j in random_indices:\n",
    "            example_image_path = all_data[0][j]\n",
    "            example_image_base64 = load_image(example_image_path)\n",
    "            examples.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{example_image_base64}\", \"detail\": \"high\"}})\n",
    "            examples.append({\"type\": \"text\", \"text\": f'{{\"prediction\": \"{all_data.at[j, 1]}\"}}' })\n",
    "\n",
    "\n",
    "        result = await get_image_informations(session, {\"image\": image_base64, \"examples\": examples})\n",
    "        prediction = result[\"choices\"][0]['message']['content']\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = json.loads(prediction)['prediction']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {all_data[0][i]}: {str(e)}\")\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = 'NA'\n",
    "\n",
    "\n",
    "async def process_images_for_shots(number_of_shots, all_data_results):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for i in range(len(all_data)):#range(0, min(samples_to_run, len(all_data))):\n",
    "            task = asyncio.ensure_future(process_image(session, i, number_of_shots, all_data_results))\n",
    "            tasks.append(task)\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "async def main():\n",
    "    all_data_results = all_data.copy(deep=True)\n",
    "    all_data_results.columns = all_data_results.columns.map(str)\n",
    "\n",
    "    for number_of_shots in [0, 1, 2, 4, 8]:\n",
    "        await process_images_for_shots(number_of_shots, all_data_results)\n",
    "    all_data_results.to_csv(base_directory.split(\"/\")[-1] + \".csv\")\n",
    "    # print(all_data_results.iloc[9:16])\n",
    "    print(\"done\")\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Mangoe Disease\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import time\n",
    "\n",
    "nest_asyncio.apply()\n",
    "global all_data_results\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Set the base directory\n",
    "base_directory = 'data/mango-leaf-disease-dataset'\n",
    "\n",
    "# FOR API\n",
    "max_requests_per_half_minute = 100\n",
    "\n",
    "total_samples_to_check=100\n",
    "# Define the list of expected class labels\n",
    "expected_classes = ['Anthracnose', 'Bacterial Canker', 'Cutting Weevil', 'Die Back', 'Gall Midge', 'Healthy', 'Powdery Mildew', 'Sooty Mould' ]\n",
    "\n",
    "num_instances_per_class = int(total_samples_to_check/len(expected_classes))\n",
    "# Create empty lists to store file paths and labels\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "# Loop through all subdirectories in the base directory\n",
    "for subdir in os.listdir(base_directory):\n",
    "    if subdir==\".DS_Store\":\n",
    "        continue\n",
    "    # if subdir in expected_classes:\n",
    "    subdir_path = os.path.join(base_directory, subdir)\n",
    "    # Loop through all files in the subdirectory\n",
    "    for filename in os.listdir(subdir_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            # Append the file path and label to the respective lists\n",
    "            file_paths.append(os.path.join(subdir_path, filename))\n",
    "            labels.append(subdir)\n",
    "\n",
    "# Create a dataframe from the lists\n",
    "data = pd.DataFrame({0: file_paths, 1: labels})\n",
    "\n",
    "# Get the unique classes\n",
    "unique_classes = data[1].unique()\n",
    "\n",
    "# Create a new dataframe with sampled data\n",
    "sampled_data = pd.DataFrame(columns=[0, 1])\n",
    "\n",
    "# Sample uniformly from each class\n",
    "for cls in unique_classes:\n",
    "    class_data = data[data[1] == cls].sample(n=num_instances_per_class, random_state=42)\n",
    "    sampled_data = pd.concat([sampled_data, class_data], ignore_index=True)\n",
    "\n",
    "# Shuffle the sampled data\n",
    "all_data = shuffle(sampled_data, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "def load_image(image_path: str) -> str:\n",
    "    \"\"\"Load image from file and encode it as base64.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model =\"gpt-4o-2024-05-13\" #\"gpt-4-turbo\"\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "vision_prompt = f\"\"\"\n",
    "Given the image, identify the class. Use the following list of possible classes for your prediction It should be one of the : {expected_classes}. Be attentive to subtle details as some classes may appear similar. Provide your answer in the following JSON format:\n",
    "{{\"prediction\": \"class_name\"}}\n",
    "Replace \"class_name\" with the appropriate class from the list above based on your analysis of the image.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "request_times = []\n",
    "\n",
    "async def get_image_informations(session, inputs: dict) -> dict:\n",
    "    \"\"\"Invoke model with image and prompt.\"\"\"\n",
    "    global request_times\n",
    "    \n",
    "    while True:\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Remove old request times outside the current time window\n",
    "        while request_times and request_times[0] <= current_time - 30:\n",
    "            request_times.pop(0)\n",
    "        \n",
    "        if len(request_times) < max_requests_per_half_minute:\n",
    "            request_times.append(current_time)\n",
    "            break\n",
    "        else:\n",
    "            # If the rate limit is exceeded, wait for a short duration before checking again\n",
    "            await asyncio.sleep(1)\n",
    "    \n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"response_format\":{ \"type\": \"json_object\" },\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": vision_prompt},\n",
    "                    *inputs['examples'],\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{inputs['image']}\",\n",
    "                            \"detail\": \"high\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "    async with session.post(url, headers=headers, json=payload) as response:\n",
    "        result = await response.json()\n",
    "        print(result)\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            return result\n",
    "        else:\n",
    "            raise Exception(\"Unexpected API response format\")\n",
    "\n",
    "async def process_image(session, i, number_of_shots, all_data_results):\n",
    "    try:\n",
    "        image_path = all_data[0][i]\n",
    "        image_base64 = load_image(image_path)\n",
    "        examples = []\n",
    "\n",
    "        # Get the number of rows in all_data\n",
    "        num_rows = len(all_data)\n",
    "\n",
    "        # Select random indices from the dataframe\n",
    "        random_indices = random.sample([idx for idx in range(num_rows) if idx != i], number_of_shots)\n",
    "\n",
    "        for j in random_indices:\n",
    "            example_image_path = all_data[0][j]\n",
    "            example_image_base64 = load_image(example_image_path)\n",
    "            examples.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{example_image_base64}\", \"detail\": \"high\"}})\n",
    "            examples.append({\"type\": \"text\", \"text\": f'{{\"prediction\": \"{all_data.at[j, 1]}\"}}' })\n",
    "\n",
    "\n",
    "        result = await get_image_informations(session, {\"image\": image_base64, \"examples\": examples})\n",
    "        prediction = result[\"choices\"][0]['message']['content']\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = json.loads(prediction)['prediction']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {all_data[0][i]}: {str(e)}\")\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = 'NA'\n",
    "\n",
    "\n",
    "async def process_images_for_shots(number_of_shots, all_data_results):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for i in range(len(all_data)):#range(0, min(samples_to_run, len(all_data))):\n",
    "            task = asyncio.ensure_future(process_image(session, i, number_of_shots, all_data_results))\n",
    "            tasks.append(task)\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "async def main():\n",
    "    all_data_results = all_data.copy(deep=True)\n",
    "    all_data_results.columns = all_data_results.columns.map(str)\n",
    "\n",
    "    for number_of_shots in [0, 1, 2, 4, 8]:\n",
    "        await process_images_for_shots(number_of_shots, all_data_results)\n",
    "    all_data_results.to_csv(base_directory.split(\"/\")[-1] + \".csv\")\n",
    "    # print(all_data_results.iloc[9:16])\n",
    "    print(\"done\")\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Durum Wheat Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import time\n",
    "\n",
    "nest_asyncio.apply()\n",
    "global all_data_results\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Set the base directory\n",
    "base_directory = 'DIRECTORY/AgEval-datasets/Durum_Wheat_Dataset/Dataset2-Durum Wheat Video Images/processed'\n",
    "\n",
    "# FOR API\n",
    "max_requests_per_half_minute = 100\n",
    "\n",
    "total_samples_to_check=100\n",
    "# Define the list of expected class labels\n",
    "expected_classes = ['Foreign Matters', 'Starchy Kernels', 'Vitreous Kernels' ]\n",
    "\n",
    "num_instances_per_class = int(total_samples_to_check/len(expected_classes))\n",
    "# Create empty lists to store file paths and labels\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "# Loop through all subdirectories in the base directory\n",
    "for subdir in os.listdir(base_directory):\n",
    "    if subdir==\".DS_Store\":\n",
    "        continue\n",
    "    # if subdir in expected_classes:\n",
    "    subdir_path = os.path.join(base_directory, subdir)\n",
    "    # Loop through all files in the subdirectory\n",
    "    for filename in os.listdir(subdir_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            # Append the file path and label to the respective lists\n",
    "            file_paths.append(os.path.join(subdir_path, filename))\n",
    "            labels.append(subdir)\n",
    "\n",
    "# Create a dataframe from the lists\n",
    "data = pd.DataFrame({0: file_paths, 1: labels})\n",
    "\n",
    "# Get the unique classes\n",
    "unique_classes = data[1].unique()\n",
    "\n",
    "# Create a new dataframe with sampled data\n",
    "sampled_data = pd.DataFrame(columns=[0, 1])\n",
    "\n",
    "# Sample uniformly from each class\n",
    "for cls in unique_classes:\n",
    "    class_data = data[data[1] == cls].sample(n=num_instances_per_class, random_state=42)\n",
    "    sampled_data = pd.concat([sampled_data, class_data], ignore_index=True)\n",
    "\n",
    "# Shuffle the sampled data\n",
    "all_data = shuffle(sampled_data, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "def load_image(image_path: str) -> str:\n",
    "    \"\"\"Load image from file and encode it as base64.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model =\"gpt-4o-2024-05-13\" #\"gpt-4-turbo\"\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "vision_prompt = f\"\"\"\n",
    "Given the image, identify the class. Use the following list of possible classes for your prediction It should be one of the : {expected_classes}. Be attentive to subtle details as some classes may appear similar. Provide your answer in the following JSON format:\n",
    "{{\"prediction\": \"class_name\"}}\n",
    "Replace \"class_name\" with the appropriate class from the list above based on your analysis of the image.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "request_times = []\n",
    "\n",
    "async def get_image_informations(session, inputs: dict) -> dict:\n",
    "    \"\"\"Invoke model with image and prompt.\"\"\"\n",
    "    global request_times\n",
    "    \n",
    "    while True:\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Remove old request times outside the current time window\n",
    "        while request_times and request_times[0] <= current_time - 30:\n",
    "            request_times.pop(0)\n",
    "        \n",
    "        if len(request_times) < max_requests_per_half_minute:\n",
    "            request_times.append(current_time)\n",
    "            break\n",
    "        else:\n",
    "            # If the rate limit is exceeded, wait for a short duration before checking again\n",
    "            await asyncio.sleep(1)\n",
    "    \n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"response_format\":{ \"type\": \"json_object\" },\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": vision_prompt},\n",
    "                    *inputs['examples'],\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{inputs['image']}\",\n",
    "                            \"detail\": \"high\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "    async with session.post(url, headers=headers, json=payload) as response:\n",
    "        result = await response.json()\n",
    "        print(result)\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            return result\n",
    "        else:\n",
    "            raise Exception(\"Unexpected API response format\")\n",
    "\n",
    "async def process_image(session, i, number_of_shots, all_data_results):\n",
    "    try:\n",
    "        image_path = all_data[0][i]\n",
    "        image_base64 = load_image(image_path)\n",
    "        examples = []\n",
    "\n",
    "        # Get the number of rows in all_data\n",
    "        num_rows = len(all_data)\n",
    "\n",
    "        # Select random indices from the dataframe\n",
    "        random_indices = random.sample([idx for idx in range(num_rows) if idx != i], number_of_shots)\n",
    "\n",
    "        for j in random_indices:\n",
    "            example_image_path = all_data[0][j]\n",
    "            example_image_base64 = load_image(example_image_path)\n",
    "            examples.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{example_image_base64}\", \"detail\": \"high\"}})\n",
    "            examples.append({\"type\": \"text\", \"text\": f'{{\"prediction\": \"{all_data.at[j, 1]}\"}}' })\n",
    "\n",
    "\n",
    "        result = await get_image_informations(session, {\"image\": image_base64, \"examples\": examples})\n",
    "        prediction = result[\"choices\"][0]['message']['content']\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = json.loads(prediction)['prediction']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {all_data[0][i]}: {str(e)}\")\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = 'NA'\n",
    "\n",
    "\n",
    "async def process_images_for_shots(number_of_shots, all_data_results):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for i in range(len(all_data)):#range(0, min(samples_to_run, len(all_data))):\n",
    "            task = asyncio.ensure_future(process_image(session, i, number_of_shots, all_data_results))\n",
    "            tasks.append(task)\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "async def main():\n",
    "    all_data_results = all_data.copy(deep=True)\n",
    "    all_data_results.columns = all_data_results.columns.map(str)\n",
    "\n",
    "    for number_of_shots in [0, 1, 2, 4, 8]:\n",
    "        await process_images_for_shots(number_of_shots, all_data_results)\n",
    "    all_data_results.to_csv(base_directory.split(\"/\")[-1] + \".csv\")\n",
    "    # print(all_data_results.iloc[9:16])\n",
    "    print(\"done\")\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Bean Leaf Lesions Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import time\n",
    "\n",
    "nest_asyncio.apply()\n",
    "global all_data_results\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Set the base directory\n",
    "base_directory = 'DIRECTORY/AgEval-datasets/bean-leaf-lesions-classification/train'\n",
    "\n",
    "# FOR API\n",
    "max_requests_per_half_minute = 100\n",
    "\n",
    "total_samples_to_check=100\n",
    "# Define the list of expected class labels\n",
    "expected_classes = ['Angular Leaf Spot', 'Bean Rust', 'Healthy' ]\n",
    "\n",
    "num_instances_per_class = int(total_samples_to_check/len(expected_classes))\n",
    "# Create empty lists to store file paths and labels\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "# Loop through all subdirectories in the base directory\n",
    "for subdir in os.listdir(base_directory):\n",
    "    if subdir==\".DS_Store\":\n",
    "        continue\n",
    "    # if subdir in expected_classes:\n",
    "    subdir_path = os.path.join(base_directory, subdir)\n",
    "    # Loop through all files in the subdirectory\n",
    "    for filename in os.listdir(subdir_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            # Append the file path and label to the respective lists\n",
    "            file_paths.append(os.path.join(subdir_path, filename))\n",
    "            labels.append(subdir)\n",
    "\n",
    "# Create a dataframe from the lists\n",
    "data = pd.DataFrame({0: file_paths, 1: labels})\n",
    "\n",
    "# Get the unique classes\n",
    "unique_classes = data[1].unique()\n",
    "\n",
    "# Create a new dataframe with sampled data\n",
    "sampled_data = pd.DataFrame(columns=[0, 1])\n",
    "\n",
    "# Sample uniformly from each class\n",
    "for cls in unique_classes:\n",
    "    class_data = data[data[1] == cls].sample(n=num_instances_per_class, random_state=42)\n",
    "    sampled_data = pd.concat([sampled_data, class_data], ignore_index=True)\n",
    "\n",
    "# Shuffle the sampled data\n",
    "all_data = shuffle(sampled_data, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "def load_image(image_path: str) -> str:\n",
    "    \"\"\"Load image from file and encode it as base64.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model =\"gpt-4o-2024-05-13\" #\"gpt-4-turbo\"\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "vision_prompt = f\"\"\"\n",
    "Given the image, identify the class. Use the following list of possible classes for your prediction It should be one of the : {expected_classes}. Be attentive to subtle details as some classes may appear similar. Provide your answer in the following JSON format:\n",
    "{{\"prediction\": \"class_name\"}}\n",
    "Replace \"class_name\" with the appropriate class from the list above based on your analysis of the image.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "request_times = []\n",
    "\n",
    "async def get_image_informations(session, inputs: dict) -> dict:\n",
    "    \"\"\"Invoke model with image and prompt.\"\"\"\n",
    "    global request_times\n",
    "    \n",
    "    while True:\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Remove old request times outside the current time window\n",
    "        while request_times and request_times[0] <= current_time - 30:\n",
    "            request_times.pop(0)\n",
    "        \n",
    "        if len(request_times) < max_requests_per_half_minute:\n",
    "            request_times.append(current_time)\n",
    "            break\n",
    "        else:\n",
    "            # If the rate limit is exceeded, wait for a short duration before checking again\n",
    "            await asyncio.sleep(1)\n",
    "    \n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"response_format\":{ \"type\": \"json_object\" },\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": vision_prompt},\n",
    "                    *inputs['examples'],\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{inputs['image']}\",\n",
    "                            \"detail\": \"high\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "    async with session.post(url, headers=headers, json=payload) as response:\n",
    "        result = await response.json()\n",
    "        print(result)\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            return result\n",
    "        else:\n",
    "            raise Exception(\"Unexpected API response format\")\n",
    "\n",
    "async def process_image(session, i, number_of_shots, all_data_results):\n",
    "    try:\n",
    "        image_path = all_data[0][i]\n",
    "        image_base64 = load_image(image_path)\n",
    "        examples = []\n",
    "\n",
    "        # Get the number of rows in all_data\n",
    "        num_rows = len(all_data)\n",
    "\n",
    "        # Select random indices from the dataframe\n",
    "        random_indices = random.sample([idx for idx in range(num_rows) if idx != i], number_of_shots)\n",
    "\n",
    "        for j in random_indices:\n",
    "            example_image_path = all_data[0][j]\n",
    "            example_image_base64 = load_image(example_image_path)\n",
    "            examples.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{example_image_base64}\", \"detail\": \"high\"}})\n",
    "            examples.append({\"type\": \"text\", \"text\": f'{{\"prediction\": \"{all_data.at[j, 1]}\"}}' })\n",
    "\n",
    "\n",
    "        result = await get_image_informations(session, {\"image\": image_base64, \"examples\": examples})\n",
    "        prediction = result[\"choices\"][0]['message']['content']\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = json.loads(prediction)['prediction']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {all_data[0][i]}: {str(e)}\")\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = 'NA'\n",
    "\n",
    "\n",
    "async def process_images_for_shots(number_of_shots, all_data_results):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for i in range(len(all_data)):#range(0, min(samples_to_run, len(all_data))):\n",
    "            task = asyncio.ensure_future(process_image(session, i, number_of_shots, all_data_results))\n",
    "            tasks.append(task)\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "async def main():\n",
    "    all_data_results = all_data.copy(deep=True)\n",
    "    all_data_results.columns = all_data_results.columns.map(str)\n",
    "\n",
    "    for number_of_shots in [0, 1, 2, 4, 8]:\n",
    "        await process_images_for_shots(number_of_shots, all_data_results)\n",
    "    all_data_results.to_csv(base_directory.split(\"/\")[-1] + \".csv\")\n",
    "    # print(all_data_results.iloc[9:16])\n",
    "    print(\"done\")\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. DeeWeeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import time\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "nest_asyncio.apply()\n",
    "global all_data_results\n",
    "\n",
    "# Set the base directory\n",
    "base_directory = 'DIRECTORY/AgEval-datasets/deepweeds'\n",
    "\n",
    "# FOR API\n",
    "max_requests_per_half_minute = 100\n",
    "\n",
    "total_samples_to_check = 100\n",
    "\n",
    "# Load the labels CSV file\n",
    "labels_df = pd.read_csv(os.path.join(base_directory, 'labels', 'labels.csv'))\n",
    "\n",
    "# Get the unique classes (species)\n",
    "expected_classes = ['Chinee apple', 'Lantana', 'Negative', 'Snake weed', 'Siam weed', 'Prickly acacia', 'Parthenium', 'Rubber vine', 'Parkinsonia']\n",
    "\n",
    "#labels_df['Species'].unique().tolist()\n",
    "\n",
    "num_instances_per_class = int(total_samples_to_check / len(expected_classes))\n",
    "\n",
    "# Create a dataframe with file paths and labels\n",
    "data = pd.DataFrame({\n",
    "    'file_path': labels_df['Filename'].apply(lambda x: os.path.join(base_directory, 'images', x)),\n",
    "    'label': labels_df['Species']\n",
    "})\n",
    "\n",
    "# Sample uniformly from each class\n",
    "sampled_data = pd.DataFrame(columns=['file_path', 'label'])\n",
    "for cls in expected_classes:\n",
    "    class_data = data[data['label'] == cls].sample(n=num_instances_per_class, random_state=42)\n",
    "    sampled_data = pd.concat([sampled_data, class_data], ignore_index=True)\n",
    "\n",
    "# Shuffle the sampled data\n",
    "all_data = shuffle(sampled_data, random_state=42).reset_index(drop=True)\n",
    "\n",
    "def load_image(image_path: str) -> str:\n",
    "    \"\"\"Load image from file and encode it as base64.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model = \"gpt-4o-2024-05-13\"  # \"gpt-4-turbo\"\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "vision_prompt = f\"\"\"\n",
    "Given the image, identify the species of weed. Use the following list of possible classes for your prediction: {expected_classes}. Be attentive to subtle details as some classes may appear similar. Provide your answer in the following JSON format:\n",
    "{{\"prediction\": \"species_name\"}}\n",
    "Replace \"species_name\" with the appropriate species from the list above based on your analysis of the image.\n",
    "\"\"\"\n",
    "\n",
    "request_times = []\n",
    "\n",
    "async def get_image_informations(session, inputs: dict) -> dict:\n",
    "    \"\"\"Invoke model with image and prompt.\"\"\"\n",
    "    global request_times\n",
    "    \n",
    "    while True:\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Remove old request times outside the current time window\n",
    "        while request_times and request_times[0] <= current_time - 30:\n",
    "            request_times.pop(0)\n",
    "        \n",
    "        if len(request_times) < max_requests_per_half_minute:\n",
    "            request_times.append(current_time)\n",
    "            break\n",
    "        else:\n",
    "            # If the rate limit is exceeded, wait for a short duration before checking again\n",
    "            await asyncio.sleep(1)\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"response_format\": {\"type\": \"json_object\"},\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": vision_prompt},\n",
    "                    *inputs['examples'],\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{inputs['image']}\",\n",
    "                            \"detail\": \"high\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "    async with session.post(url, headers=headers, json=payload) as response:\n",
    "        result = await response.json()\n",
    "        print(result)\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            return result\n",
    "        else:\n",
    "            raise Exception(\"Unexpected API response format\")\n",
    "\n",
    "async def process_image(session, i, number_of_shots, all_data_results):\n",
    "    try:\n",
    "        image_path = all_data['file_path'][i]\n",
    "        image_base64 = load_image(image_path)\n",
    "        examples = []\n",
    "\n",
    "        # Get the number of rows in all_data\n",
    "        num_rows = len(all_data)\n",
    "\n",
    "        # Select random indices from the dataframe\n",
    "        random_indices = random.sample([idx for idx in range(num_rows) if idx != i], number_of_shots)\n",
    "\n",
    "        for j in random_indices:\n",
    "            example_image_path = all_data['file_path'][j]\n",
    "            example_image_base64 = load_image(example_image_path)\n",
    "            examples.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{example_image_base64}\", \"detail\": \"high\"}})\n",
    "            examples.append({\"type\": \"text\", \"text\": f'{{\"prediction\": \"{all_data.at[j, \"label\"]}\"}}' })\n",
    "\n",
    "        result = await get_image_informations(session, {\"image\": image_base64, \"examples\": examples})\n",
    "        prediction = result[\"choices\"][0]['message']['content']\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = json.loads(prediction)['prediction']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {all_data['file_path'][i]}: {str(e)}\")\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = 'NA'\n",
    "\n",
    "async def process_images_for_shots(number_of_shots, all_data_results):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for i in range(len(all_data)):\n",
    "            task = asyncio.ensure_future(process_image(session, i, number_of_shots, all_data_results))\n",
    "            tasks.append(task)\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "async def main():\n",
    "    all_data_results = all_data.copy(deep=True)\n",
    "\n",
    "    for number_of_shots in [0, 1, 2, 4, 8]:\n",
    "        await process_images_for_shots(number_of_shots, all_data_results)\n",
    "    all_data_results.to_csv(base_directory.split(\"/\")[-1] + \".csv\")\n",
    "    print(\"done\")\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IP102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import time\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "nest_asyncio.apply()\n",
    "global all_data_results\n",
    "\n",
    "# Set the base directory\n",
    "base_directory = 'DIRECTORY/AgEval-datasets/ip02-dataset/classification/train'\n",
    "classes_file = 'DIRECTORY/AgEval-datasets/ip02-dataset/classes.txt'\n",
    "\n",
    "# FOR API\n",
    "max_requests_per_half_minute = 100\n",
    "\n",
    "total_samples_to_check = 102*3\n",
    "\n",
    "# Read the classes from the txt file\n",
    "def read_classes(file_path):\n",
    "    classes = {}\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(maxsplit=1)\n",
    "            if len(parts) == 2:\n",
    "                class_id, class_name = parts\n",
    "                classes[int(class_id) - 1] = class_name.strip()  # Subtract 1 to match folder names\n",
    "    return classes\n",
    "\n",
    "expected_classes = read_classes(classes_file)\n",
    "\n",
    "num_instances_per_class = int(total_samples_to_check / len(expected_classes))\n",
    "\n",
    "# Create empty lists to store file paths and labels\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "# Loop through all subdirectories in the base directory\n",
    "for subdir in os.listdir(base_directory):\n",
    "    if subdir == \".DS_Store\":\n",
    "        continue\n",
    "    subdir_path = os.path.join(base_directory, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        # Loop through all files in the subdirectory\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "                # Append the file path and label to the respective lists\n",
    "                file_paths.append(os.path.join(subdir_path, filename))\n",
    "                labels.append(expected_classes[int(subdir)])\n",
    "\n",
    "# Create a dataframe from the lists\n",
    "data = pd.DataFrame({0: file_paths, 1: labels})\n",
    "\n",
    "# Get the unique classes\n",
    "unique_classes = data[1].unique()\n",
    "\n",
    "# Create a new dataframe with sampled data\n",
    "sampled_data = pd.DataFrame(columns=[0, 1])\n",
    "\n",
    "# Sample uniformly from each class\n",
    "for cls in unique_classes:\n",
    "    class_data = data[data[1] == cls].sample(n=min(num_instances_per_class, len(data[data[1] == cls])), random_state=42)\n",
    "    sampled_data = pd.concat([sampled_data, class_data], ignore_index=True)\n",
    "\n",
    "# Shuffle the sampled data\n",
    "all_data = shuffle(sampled_data, random_state=42).reset_index(drop=True)\n",
    "\n",
    "def load_image(image_path: str) -> str:\n",
    "    \"\"\"Load image from file and encode it as base64.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model = \"gpt-4o-2024-05-13\"  # \"gpt-4-turbo\"\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "vision_prompt = f\"\"\"\n",
    "Given the image, identify the class. Use the following list of possible classes for your prediction: {list(expected_classes.values())}. Be attentive to subtle details as some classes may appear similar. Provide your answer in the following JSON format:\n",
    "{{\"prediction\": \"class_name\"}}\n",
    "Replace \"class_name\" with the appropriate class from the list above based on your analysis of the image.\n",
    "\"\"\"\n",
    "\n",
    "request_times = []\n",
    "\n",
    "async def get_image_informations(session, inputs: dict) -> dict:\n",
    "    \"\"\"Invoke model with image and prompt.\"\"\"\n",
    "    global request_times\n",
    "    \n",
    "    while True:\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Remove old request times outside the current time window\n",
    "        while request_times and request_times[0] <= current_time - 30:\n",
    "            request_times.pop(0)\n",
    "        \n",
    "        if len(request_times) < max_requests_per_half_minute:\n",
    "            request_times.append(current_time)\n",
    "            break\n",
    "        else:\n",
    "            # If the rate limit is exceeded, wait for a short duration before checking again\n",
    "            await asyncio.sleep(1)\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"response_format\":{ \"type\": \"json_object\" },\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": vision_prompt},\n",
    "                    *inputs['examples'],\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{inputs['image']}\",\n",
    "                            \"detail\": \"high\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "    async with session.post(url, headers=headers, json=payload) as response:\n",
    "        result = await response.json()\n",
    "        print(result)\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            return result\n",
    "        else:\n",
    "            raise Exception(\"Unexpected API response format\")\n",
    "\n",
    "async def process_image(session, i, number_of_shots, all_data_results):\n",
    "    try:\n",
    "        image_path = all_data[0][i]\n",
    "        image_base64 = load_image(image_path)\n",
    "        examples = []\n",
    "        example_paths = []\n",
    "        example_categories = []\n",
    "\n",
    "        # Get the number of rows in all_data\n",
    "        num_rows = len(all_data)\n",
    "\n",
    "        # Select random indices from the dataframe\n",
    "        random_indices = random.sample([idx for idx in range(num_rows) if idx != i], number_of_shots)\n",
    "\n",
    "        for j in random_indices:\n",
    "            example_image_path = all_data[0][j]\n",
    "            example_category = all_data[1][j]\n",
    "            example_image_base64 = load_image(example_image_path)\n",
    "            examples.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{example_image_base64}\", \"detail\": \"high\"}})\n",
    "            examples.append({\"type\": \"text\", \"text\": f'{{\"prediction\": \"{example_category}\"}}' })\n",
    "            example_paths.append(example_image_path)\n",
    "            example_categories.append(example_category)\n",
    "\n",
    "        result = await get_image_informations(session, {\"image\": image_base64, \"examples\": examples})\n",
    "        prediction = result[\"choices\"][0]['message']['content']\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = json.loads(prediction)['prediction']\n",
    "        all_data_results.at[i, f\"Example Paths {number_of_shots}\"] = json.dumps(example_paths)\n",
    "        all_data_results.at[i, f\"Example Categories {number_of_shots}\"] = json.dumps(example_categories)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {all_data[0][i]}: {str(e)}\")\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = 'NA'\n",
    "        all_data_results.at[i, f\"Example Paths {number_of_shots}\"] = 'NA'\n",
    "        all_data_results.at[i, f\"Example Categories {number_of_shots}\"] = 'NA'\n",
    "\n",
    "async def process_images_for_shots(number_of_shots, all_data_results):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for i in range(len(all_data)):\n",
    "            task = asyncio.ensure_future(process_image(session, i, number_of_shots, all_data_results))\n",
    "            tasks.append(task)\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "async def main():\n",
    "    all_data_results = all_data.copy(deep=True)\n",
    "    all_data_results.columns = all_data_results.columns.map(str)\n",
    "\n",
    "    for number_of_shots in [0,1, 2, 4, 8]:\n",
    "        await process_images_for_shots(number_of_shots, all_data_results)\n",
    "    all_data_results.to_csv(\"ip02-dataset-results.csv\")\n",
    "    print(\"done\")\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yellow Rust 19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import time\n",
    "\n",
    "nest_asyncio.apply()\n",
    "global all_data_results\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Set the base directory\n",
    "base_directory = 'DIRECTORY/AgEval-datasets/yellowrust19-yellow-rust-disease-in-wheat/YELLOW-RUST-19/YELLOW-RUST-19'\n",
    "\n",
    "# FOR API\n",
    "max_requests_per_half_minute = 100\n",
    "\n",
    "total_samples_to_check=100\n",
    "# Define the list of expected class labels\n",
    "expected_classes = ['Moderately Resistant (MR)', 'Moderately Susceptible (MS)', 'MRMS', 'No disease (0)', 'Resistant (R)', 'Susceptible (S)' ]\n",
    "\n",
    "num_instances_per_class = int(total_samples_to_check/len(expected_classes))\n",
    "# Create empty lists to store file paths and labels\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "# Loop through all subdirectories in the base directory\n",
    "for subdir in os.listdir(base_directory):\n",
    "    if subdir==\".DS_Store\":\n",
    "        continue\n",
    "    # if subdir in expected_classes:\n",
    "    subdir_path = os.path.join(base_directory, subdir)\n",
    "    # Loop through all files in the subdirectory\n",
    "    for filename in os.listdir(subdir_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            # Append the file path and label to the respective lists\n",
    "            file_paths.append(os.path.join(subdir_path, filename))\n",
    "            labels.append(subdir)\n",
    "\n",
    "# Create a dataframe from the lists\n",
    "data = pd.DataFrame({0: file_paths, 1: labels})\n",
    "\n",
    "# Get the unique classes\n",
    "unique_classes = data[1].unique()\n",
    "\n",
    "# Create a new dataframe with sampled data\n",
    "sampled_data = pd.DataFrame(columns=[0, 1])\n",
    "\n",
    "# Sample uniformly from each class\n",
    "for cls in unique_classes:\n",
    "    class_data = data[data[1] == cls].sample(n=num_instances_per_class, random_state=42)\n",
    "    sampled_data = pd.concat([sampled_data, class_data], ignore_index=True)\n",
    "\n",
    "# Shuffle the sampled data\n",
    "all_data = shuffle(sampled_data, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "def load_image(image_path: str) -> str:\n",
    "    \"\"\"Load image from file and encode it as base64.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model =\"gpt-4o-2024-05-13\" #\"gpt-4-turbo\"\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "vision_prompt = f\"\"\"\n",
    "Given the image, identify the class. Use the following list of possible classes for your prediction It should be one of the : {expected_classes}. Be attentive to subtle details as some classes may appear similar. Provide your answer in the following JSON format:\n",
    "{{\"prediction\": \"class_name\"}}\n",
    "Replace \"class_name\" with the appropriate class from the list above based on your analysis of the image.\n",
    "Please note that: \n",
    "No disease (0: No signs of infection),\n",
    "Resistant (R: Minor signs of infection),\n",
    "Moderately Resistant (MR: Small and medium signs of infection),\n",
    "Moderately Resistant-Moderately Susceptible (MRMS),\n",
    "Moderately Susceptible (MS: Medium signs of infection) and\n",
    "Susceptible (S: Major signs of infection)\n",
    "The labels should be entered exactly as they are in the list above i.e., {expected_classes}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "request_times = []\n",
    "\n",
    "async def get_image_informations(session, inputs: dict) -> dict:\n",
    "    \"\"\"Invoke model with image and prompt.\"\"\"\n",
    "    global request_times\n",
    "    \n",
    "    while True:\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Remove old request times outside the current time window\n",
    "        while request_times and request_times[0] <= current_time - 30:\n",
    "            request_times.pop(0)\n",
    "        \n",
    "        if len(request_times) < max_requests_per_half_minute:\n",
    "            request_times.append(current_time)\n",
    "            break\n",
    "        else:\n",
    "            # If the rate limit is exceeded, wait for a short duration before checking again\n",
    "            await asyncio.sleep(1)\n",
    "    \n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"response_format\":{ \"type\": \"json_object\" },\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": vision_prompt},\n",
    "                    *inputs['examples'],\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{inputs['image']}\",\n",
    "                            \"detail\": \"high\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "    async with session.post(url, headers=headers, json=payload) as response:\n",
    "        result = await response.json()\n",
    "        print(result)\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            return result\n",
    "        else:\n",
    "            raise Exception(\"Unexpected API response format\")\n",
    "\n",
    "async def process_image(session, i, number_of_shots, all_data_results):\n",
    "    try:\n",
    "        image_path = all_data[0][i]\n",
    "        image_base64 = load_image(image_path)\n",
    "        examples = []\n",
    "\n",
    "        # Get the number of rows in all_data\n",
    "        num_rows = len(all_data)\n",
    "\n",
    "        # Select random indices from the dataframe\n",
    "        random_indices = random.sample([idx for idx in range(num_rows) if idx != i], number_of_shots)\n",
    "\n",
    "        for j in random_indices:\n",
    "            example_image_path = all_data[0][j]\n",
    "            example_image_base64 = load_image(example_image_path)\n",
    "            examples.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{example_image_base64}\", \"detail\": \"high\"}})\n",
    "            examples.append({\"type\": \"text\", \"text\": f'{{\"prediction\": \"{all_data.at[j, 1]}\"}}' })\n",
    "\n",
    "\n",
    "        result = await get_image_informations(session, {\"image\": image_base64, \"examples\": examples})\n",
    "        prediction = result[\"choices\"][0]['message']['content']\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = json.loads(prediction)['prediction']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {all_data[0][i]}: {str(e)}\")\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = 'NA'\n",
    "\n",
    "\n",
    "async def process_images_for_shots(number_of_shots, all_data_results):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for i in range(len(all_data)):#range(0, min(samples_to_run, len(all_data))):\n",
    "            task = asyncio.ensure_future(process_image(session, i, number_of_shots, all_data_results))\n",
    "            tasks.append(task)\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "async def main():\n",
    "    all_data_results = all_data.copy(deep=True)\n",
    "    all_data_results.columns = all_data_results.columns.map(str)\n",
    "\n",
    "    for number_of_shots in [0, 1, 2, 4, 8]:\n",
    "        await process_images_for_shots(number_of_shots, all_data_results)\n",
    "    all_data_results.to_csv(base_directory.split(\"/\")[-1] + \".csv\")\n",
    "    # print(all_data_results.iloc[9:16])\n",
    "    print(\"done\")\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusarium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import time\n",
    "\n",
    "nest_asyncio.apply()\n",
    "global all_data_results\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Set the base directory\n",
    "base_directory = 'DIRECTORY/AgEval-datasets/FUSARIUM-22/dataset_raw'\n",
    "# FOR API\n",
    "max_requests_per_half_minute = 100\n",
    "\n",
    "total_samples_to_check=100\n",
    "# Define the list of expected class labels\n",
    "expected_classes = ['Highly Resistant', 'Highly Susceptible', 'Moderately Resistant', 'Resistant', 'Susceptible' ]\n",
    "\n",
    "num_instances_per_class = int(total_samples_to_check/len(expected_classes))\n",
    "# Create empty lists to store file paths and labels\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "# Loop through all subdirectories in the base directory\n",
    "for subdir in os.listdir(base_directory):\n",
    "    if subdir==\".DS_Store\":\n",
    "        continue\n",
    "    # if subdir in expected_classes:\n",
    "    subdir_path = os.path.join(base_directory, subdir)\n",
    "    # Loop through all files in the subdirectory\n",
    "    for filename in os.listdir(subdir_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            # Append the file path and label to the respective lists\n",
    "            file_paths.append(os.path.join(subdir_path, filename))\n",
    "            labels.append(subdir)\n",
    "\n",
    "# Create a dataframe from the lists\n",
    "data = pd.DataFrame({0: file_paths, 1: labels})\n",
    "\n",
    "# Get the unique classes\n",
    "unique_classes = data[1].unique()\n",
    "\n",
    "# Create a new dataframe with sampled data\n",
    "sampled_data = pd.DataFrame(columns=[0, 1])\n",
    "\n",
    "# Sample uniformly from each class\n",
    "for cls in unique_classes:\n",
    "    class_data = data[data[1] == cls].sample(n=num_instances_per_class, random_state=42)\n",
    "    sampled_data = pd.concat([sampled_data, class_data], ignore_index=True)\n",
    "\n",
    "# Shuffle the sampled data\n",
    "all_data = shuffle(sampled_data, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "def load_image(image_path: str) -> str:\n",
    "    \"\"\"Load image from file and encode it as base64.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model =\"gpt-4o-2024-05-13\" #\"gpt-4-turbo\"\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "vision_prompt = f\"\"\"\n",
    "Given the image, identify the class. Use the following list of possible classes for your prediction It should be one of the : {expected_classes}. Be attentive to subtle details as some classes may appear similar. Provide your answer in the following JSON format:\n",
    "{{\"prediction\": \"class_name\"}}\n",
    "Replace \"class_name\" with the appropriate class from the list above based on your analysis of the image.\n",
    "Please note that: \n",
    "Severity level images from the dataset:\n",
    "1: Highly Resistant (HR): The plant has been wilted by 0%-10%,\n",
    "3: Resistant (R): The plant has been wilted by 11%-20%,\n",
    "5: Moderately Resistant/ Tolerant (MR): The plant has been wilted by 21%-30%,\n",
    "7: Susceptible (S): The plant has been wilted by 31%-50%,\n",
    "9: Highly Susceptible (HS): The plant has been wilted by more than 51%\n",
    "The labels should be entered exactly as they are in the list above i.e., {expected_classes}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "request_times = []\n",
    "\n",
    "async def get_image_informations(session, inputs: dict) -> dict:\n",
    "    \"\"\"Invoke model with image and prompt.\"\"\"\n",
    "    global request_times\n",
    "    \n",
    "    while True:\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Remove old request times outside the current time window\n",
    "        while request_times and request_times[0] <= current_time - 30:\n",
    "            request_times.pop(0)\n",
    "        \n",
    "        if len(request_times) < max_requests_per_half_minute:\n",
    "            request_times.append(current_time)\n",
    "            break\n",
    "        else:\n",
    "            # If the rate limit is exceeded, wait for a short duration before checking again\n",
    "            await asyncio.sleep(1)\n",
    "    \n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"response_format\":{ \"type\": \"json_object\" },\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": vision_prompt},\n",
    "                    *inputs['examples'],\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{inputs['image']}\",\n",
    "                            \"detail\": \"high\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "    async with session.post(url, headers=headers, json=payload) as response:\n",
    "        result = await response.json()\n",
    "        print(result)\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            return result\n",
    "        else:\n",
    "            raise Exception(\"Unexpected API response format\")\n",
    "\n",
    "async def process_image(session, i, number_of_shots, all_data_results):\n",
    "    try:\n",
    "        image_path = all_data[0][i]\n",
    "        image_base64 = load_image(image_path)\n",
    "        examples = []\n",
    "\n",
    "        # Get the number of rows in all_data\n",
    "        num_rows = len(all_data)\n",
    "\n",
    "        # Select random indices from the dataframe\n",
    "        random_indices = random.sample([idx for idx in range(num_rows) if idx != i], number_of_shots)\n",
    "\n",
    "        for j in random_indices:\n",
    "            example_image_path = all_data[0][j]\n",
    "            example_image_base64 = load_image(example_image_path)\n",
    "            examples.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{example_image_base64}\", \"detail\": \"high\"}})\n",
    "            examples.append({\"type\": \"text\", \"text\": f'{{\"prediction\": \"{all_data.at[j, 1]}\"}}' })\n",
    "\n",
    "\n",
    "        result = await get_image_informations(session, {\"image\": image_base64, \"examples\": examples})\n",
    "        prediction = result[\"choices\"][0]['message']['content']\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = json.loads(prediction)['prediction']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {all_data[0][i]}: {str(e)}\")\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = 'NA'\n",
    "\n",
    "\n",
    "async def process_images_for_shots(number_of_shots, all_data_results):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for i in range(len(all_data)):#range(0, min(samples_to_run, len(all_data))):\n",
    "            task = asyncio.ensure_future(process_image(session, i, number_of_shots, all_data_results))\n",
    "            tasks.append(task)\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "async def main():\n",
    "    all_data_results = all_data.copy(deep=True)\n",
    "    all_data_results.columns = all_data_results.columns.map(str)\n",
    "\n",
    "    for number_of_shots in [0, 1, 2, 4, 8]:\n",
    "        await process_images_for_shots(number_of_shots, all_data_results)\n",
    "    all_data_results.to_csv(\"Furasium.csv\")\n",
    "    # print(all_data_results.iloc[9:16])\n",
    "    print(\"done\")\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Severity based rice disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import time\n",
    "\n",
    "nest_asyncio.apply()\n",
    "global all_data_results\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Set the base directory\n",
    "base_directory = 'DIRECTORY/AgEval-datasets/severity-based-rice-disease/train'\n",
    "# FOR API\n",
    "max_requests_per_half_minute = 100\n",
    "\n",
    "total_samples_to_check=100\n",
    "\n",
    "# Define the list of expected class labels\n",
    "expected_classes = ['Healthy', 'Mild Bacterial Blight', 'Mild Blast', 'Mild Brownspot', 'Mild Tungro', 'Severe Bacterial Blight', 'Severe Blast', 'Severe Brownspot', 'Severe Tungro' ]\n",
    "\n",
    "num_instances_per_class = int(total_samples_to_check/len(expected_classes))\n",
    "# Create empty lists to store file paths and labels\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "# Loop through all subdirectories in the base directory\n",
    "for subdir in os.listdir(base_directory):\n",
    "    if subdir==\".DS_Store\":\n",
    "        continue\n",
    "    # if subdir in expected_classes:\n",
    "    subdir_path = os.path.join(base_directory, subdir)\n",
    "    # Loop through all files in the subdirectory\n",
    "    for filename in os.listdir(subdir_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.JPG') or filename.endswith('.PNG'):\n",
    "            # Append the file path and label to the respective lists\n",
    "            file_paths.append(os.path.join(subdir_path, filename))\n",
    "            labels.append(subdir)\n",
    "\n",
    "# Create a dataframe from the lists\n",
    "data = pd.DataFrame({0: file_paths, 1: labels})\n",
    "\n",
    "# Get the unique classes\n",
    "unique_classes = data[1].unique()\n",
    "\n",
    "# Create a new dataframe with sampled data\n",
    "sampled_data = pd.DataFrame(columns=[0, 1])\n",
    "\n",
    "# Sample uniformly from each class\n",
    "for cls in unique_classes:\n",
    "    class_data = data[data[1] == cls].sample(n=num_instances_per_class, random_state=42)\n",
    "    sampled_data = pd.concat([sampled_data, class_data], ignore_index=True)\n",
    "\n",
    "# Shuffle the sampled data\n",
    "all_data = shuffle(sampled_data, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "def load_image(image_path: str) -> str:\n",
    "    \"\"\"Load image from file and encode it as base64.\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model =\"gpt-4o-2024-05-13\" #\"gpt-4-turbo\"\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "\n",
    "vision_prompt = f\"\"\"\n",
    "Given the image, identify the class. Use the following list of possible classes for your prediction It should be one of the : {expected_classes}. Be attentive to subtle details as some classes may appear similar. Provide your answer in the following JSON format:\n",
    "{{\"prediction\": \"class_name\"}}\n",
    "Replace \"class_name\" with the appropriate class from the list above based on your analysis of the image.\n",
    "The labels should be entered exactly as they are in the list above i.e., {expected_classes}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "request_times = []\n",
    "\n",
    "async def get_image_informations(session, inputs: dict) -> dict:\n",
    "    \"\"\"Invoke model with image and prompt.\"\"\"\n",
    "    global request_times\n",
    "    \n",
    "    while True:\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Remove old request times outside the current time window\n",
    "        while request_times and request_times[0] <= current_time - 30:\n",
    "            request_times.pop(0)\n",
    "        \n",
    "        if len(request_times) < max_requests_per_half_minute:\n",
    "            request_times.append(current_time)\n",
    "            break\n",
    "        else:\n",
    "            # If the rate limit is exceeded, wait for a short duration before checking again\n",
    "            await asyncio.sleep(1)\n",
    "    \n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"response_format\":{ \"type\": \"json_object\" },\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": vision_prompt},\n",
    "                    *inputs['examples'],\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{inputs['image']}\",\n",
    "                            \"detail\": \"high\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "    async with session.post(url, headers=headers, json=payload) as response:\n",
    "        result = await response.json()\n",
    "        print(result)\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            return result\n",
    "        else:\n",
    "            raise Exception(\"Unexpected API response format\")\n",
    "\n",
    "async def process_image(session, i, number_of_shots, all_data_results):\n",
    "    try:\n",
    "        image_path = all_data[0][i]\n",
    "        image_base64 = load_image(image_path)\n",
    "        examples = []\n",
    "\n",
    "        # Get the number of rows in all_data\n",
    "        num_rows = len(all_data)\n",
    "\n",
    "        # Select random indices from the dataframe\n",
    "        random_indices = random.sample([idx for idx in range(num_rows) if idx != i], number_of_shots)\n",
    "\n",
    "        for j in random_indices:\n",
    "            example_image_path = all_data[0][j]\n",
    "            example_image_base64 = load_image(example_image_path)\n",
    "            examples.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{example_image_base64}\", \"detail\": \"high\"}})\n",
    "            examples.append({\"type\": \"text\", \"text\": f'{{\"prediction\": \"{all_data.at[j, 1]}\"}}' })\n",
    "\n",
    "\n",
    "        result = await get_image_informations(session, {\"image\": image_base64, \"examples\": examples})\n",
    "        prediction = result[\"choices\"][0]['message']['content']\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = json.loads(prediction)['prediction']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {all_data[0][i]}: {str(e)}\")\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = 'NA'\n",
    "\n",
    "\n",
    "async def process_images_for_shots(number_of_shots, all_data_results):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for i in range(len(all_data)):#range(0, min(samples_to_run, len(all_data))):\n",
    "            task = asyncio.ensure_future(process_image(session, i, number_of_shots, all_data_results))\n",
    "            tasks.append(task)\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "async def main():\n",
    "    all_data_results = all_data.copy(deep=True)\n",
    "    all_data_results.columns = all_data_results.columns.map(str)\n",
    "\n",
    "    for number_of_shots in [0, 1, 2, 4, 8]:\n",
    "        await process_images_for_shots(number_of_shots, all_data_results)\n",
    "    all_data_results.to_csv(\"SBRD.csv\")\n",
    "    # print(all_data_results.iloc[9:16])\n",
    "    print(\"done\")\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import time\n",
    "from anthropic import Anthropic\n",
    "import argparse\n",
    "from PIL import Image\n",
    "nest_asyncio.apply()\n",
    "global all_data_results\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from fuzzywuzzy import process\n",
    "import io\n",
    "# Set the base directory\n",
    "base_directory = 'DIRECTORY/AgEval-datasets/severity-based-rice-disease/train'\n",
    "model_type = 'claude'\n",
    "# FOR API\n",
    "max_requests_per_half_minute = 5\n",
    "\n",
    "total_samples_to_check = 10\n",
    "\n",
    "# Define the list of expected class labels\n",
    "expected_classes = ['Healthy', 'Mild Bacterial Blight', 'Mild Blast', 'Mild Brownspot', 'Mild Tungro', 'Severe Bacterial Blight', 'Severe Blast', 'Severe Brownspot', 'Severe Tungro']\n",
    "\n",
    "num_instances_per_class = int(total_samples_to_check/len(expected_classes))\n",
    "# Create empty lists to store file paths and labels\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "# Loop through all subdirectories in the base directory\n",
    "for subdir in os.listdir(base_directory):\n",
    "    if subdir == \".DS_Store\":\n",
    "        continue\n",
    "    subdir_path = os.path.join(base_directory, subdir)\n",
    "    # Loop through all files in the subdirectory\n",
    "    for filename in os.listdir(subdir_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.JPG') or filename.endswith('.PNG'):\n",
    "            # Append the file path and label to the respective lists\n",
    "            file_paths.append(os.path.join(subdir_path, filename))\n",
    "            labels.append(subdir)\n",
    "\n",
    "# Create a dataframe from the lists\n",
    "data = pd.DataFrame({0: file_paths, 1: labels})\n",
    "\n",
    "# Get the unique classes\n",
    "unique_classes = data[1].unique()\n",
    "\n",
    "# Create a new dataframe with sampled data\n",
    "sampled_data = pd.DataFrame(columns=[0, 1])\n",
    "\n",
    "# Sample uniformly from each class\n",
    "for cls in unique_classes:\n",
    "    class_data = data[data[1] == cls].sample(n=num_instances_per_class, random_state=42)\n",
    "    sampled_data = pd.concat([sampled_data, class_data], ignore_index=True)\n",
    "\n",
    "# Shuffle the sampled data\n",
    "all_data = shuffle(sampled_data, random_state=42).reset_index(drop=True)\n",
    "\n",
    "def load_image(image_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Load image from file, convert to JPEG, and encode as base64.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            # Convert image to RGB mode if it's not\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            # Save image to a bytes buffer as JPEG\n",
    "            buffer = io.BytesIO()\n",
    "            img.save(buffer, format=\"JPEG\", quality=85)  # You can adjust quality as needed\n",
    "            \n",
    "            # Encode the JPEG image as base64\n",
    "            return base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    \n",
    "vision_prompt = f\"\"\"\n",
    "Given the image, identify the class. Use the following list of possible classes for your prediction It should be one of the : {expected_classes}. Be attentive to subtle details as some classes may appear similar. Provide your answer in the following JSON format:\n",
    "{{\"prediction\": \"class_name\"}}\n",
    "Replace \"class_name\" with the appropriate class from the list above based on your analysis of the image.\n",
    "The labels should be entered exactly as they are in the list above i.e., {expected_classes}.\n",
    "The response should start with {{ and contain only a JSON object (as specified above) and no other text.\n",
    "\"\"\"\n",
    "\n",
    "request_times = []\n",
    "\n",
    "# Existing GPT-4 Vision function (unchanged)\n",
    "async def get_image_informations_gpt(session, inputs: dict) -> dict:\n",
    "    \"\"\"Invoke GPT-4 Vision model with image and prompt.\"\"\"\n",
    "    global request_times\n",
    "    \n",
    "    while True:\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Remove old request times outside the current time window\n",
    "        while request_times and request_times[0] <= current_time - 30:\n",
    "            request_times.pop(0)\n",
    "        \n",
    "        if len(request_times) < max_requests_per_half_minute:\n",
    "            request_times.append(current_time)\n",
    "            break\n",
    "        else:\n",
    "            # If the rate limit is exceeded, wait for a short duration before checking again\n",
    "            await asyncio.sleep(1)\n",
    "    \n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    model = \"gpt-4o-2024-05-13\"  # or \"gpt-4-turbo\"\n",
    "    url = \"https://api.openai.com/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"response_format\": {\"type\": \"json_object\"},\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": vision_prompt},\n",
    "                    *inputs['examples'],\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{inputs['image']}\",\n",
    "                            \"detail\": \"high\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "    async with session.post(url, headers=headers, json=payload) as response:\n",
    "        result = await response.json()\n",
    "        print(result)\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            return result[\"choices\"][0]['message']['content']\n",
    "        else:\n",
    "            raise Exception(\"Unexpected API response format\")\n",
    "\n",
    "# New function for Claude 3.5 Sonnet\n",
    "async def get_image_informations_claude(inputs: dict) -> str:\n",
    "    \"\"\"Invoke Claude 3.5 Sonnet model with image and prompt.\"\"\"\n",
    "    anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    anthropic_client = Anthropic(api_key=anthropic_api_key)\n",
    "    \n",
    "    def get_media_type(img_data):\n",
    "        if img_data.startswith('data:image/jpeg;base64,'):\n",
    "            return \"image/jpeg\"\n",
    "        elif img_data.startswith('data:image/png;base64,'):\n",
    "            return \"image/png\"\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported image format\")\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": vision_prompt},\n",
    "                *[\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\",\n",
    "                            \"media_type\": get_media_type(ex['image_url']['url']),\n",
    "                            \"data\": ex['image_url']['url'].split(',')[1]\n",
    "                        }\n",
    "                    }\n",
    "                    if ex['type'] == 'image_url' else ex\n",
    "                    for ex in inputs['examples']\n",
    "                ],\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": get_media_type(f\"data:image/jpeg;base64,{inputs['image']}\"),\n",
    "                        \"data\": inputs['image']\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = anthropic_client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0.3,\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.content[0].text\n",
    "\n",
    "async def process_image(session, i, number_of_shots, all_data_results, model_type):\n",
    "    try:\n",
    "        image_path = all_data[0][i]\n",
    "        image_base64 = load_image(image_path)\n",
    "        examples = []\n",
    "\n",
    "        # Get the number of rows in all_data\n",
    "        num_rows = len(all_data)\n",
    "\n",
    "        # Select random indices from the dataframe\n",
    "        random_indices = random.sample([idx for idx in range(num_rows) if idx != i], number_of_shots)\n",
    "\n",
    "        for j in random_indices:\n",
    "            example_image_path = all_data[0][j]\n",
    "            example_image_base64 = load_image(example_image_path)\n",
    "            examples.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{example_image_base64}\", \"detail\": \"high\"}})\n",
    "            examples.append({\"type\": \"text\", \"text\": f'{{\"prediction\": \"{all_data.at[j, 1]}\"}}' })\n",
    "\n",
    "        if model_type == \"gpt\":\n",
    "            prediction = await get_image_informations_gpt(session, {\"image\": image_base64, \"examples\": examples})\n",
    "        elif model_type == \"claude\":\n",
    "            prediction = await get_image_informations_claude({\"image\": image_base64, \"examples\": examples})\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = json.loads(prediction)['prediction']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {all_data[0][i]}: {str(e)}\")\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = 'NA'\n",
    "\n",
    "async def process_images_for_shots(number_of_shots, all_data_results, model_type):\n",
    "    if model_type == \"gpt\":\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            tasks = []\n",
    "            for i in range(len(all_data)):\n",
    "                task = asyncio.ensure_future(process_image(session, i, number_of_shots, all_data_results, model_type))\n",
    "                tasks.append(task)\n",
    "            await asyncio.gather(*tasks)\n",
    "    elif model_type == \"claude\":\n",
    "        for i in range(len(all_data)):\n",
    "            await process_image(None, i, number_of_shots, all_data_results, model_type)\n",
    "\n",
    "async def main():\n",
    "    all_data_results = all_data.copy(deep=True)\n",
    "    all_data_results.columns = all_data_results.columns.map(str)\n",
    "\n",
    "    for number_of_shots in [2]:  # [0, 1, 2, 4, 8]:\n",
    "        await process_images_for_shots(number_of_shots, all_data_results, model_type)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = f\"results_{model_type}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save results to the model-specific directory\n",
    "    output_file = os.path.join(output_dir, f\"SBRD_{model_type}.csv\")\n",
    "    all_data_results.to_csv(output_file)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import time\n",
    "from anthropic import Anthropic\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import io\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Set the base directory\n",
    "base_directory = 'DIRECTORY/AgEval-datasets/severity-based-rice-disease/train'\n",
    "model_type = 'claude'\n",
    "# FOR API\n",
    "max_requests_per_half_minute = 5\n",
    "\n",
    "total_samples_to_check = 10\n",
    "\n",
    "# Define the list of expected class labels\n",
    "expected_classes = ['Healthy', 'Mild Bacterial Blight', 'Mild Blast', 'Mild Brownspot', 'Mild Tungro', 'Severe Bacterial Blight', 'Severe Blast', 'Severe Brownspot', 'Severe Tungro']\n",
    "\n",
    "num_instances_per_class = int(total_samples_to_check/len(expected_classes))\n",
    "# Create empty lists to store file paths and labels\n",
    "file_paths = []\n",
    "labels = []\n",
    "\n",
    "# Loop through all subdirectories in the base directory\n",
    "for subdir in os.listdir(base_directory):\n",
    "    if subdir == \".DS_Store\":\n",
    "        continue\n",
    "    subdir_path = os.path.join(base_directory, subdir)\n",
    "    # Loop through all files in the subdirectory\n",
    "    for filename in os.listdir(subdir_path):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            # Append the file path and label to the respective lists\n",
    "            file_paths.append(os.path.join(subdir_path, filename))\n",
    "            labels.append(subdir)\n",
    "\n",
    "# Create a dataframe from the lists\n",
    "data = pd.DataFrame({0: file_paths, 1: labels})\n",
    "\n",
    "# Get the unique classes\n",
    "unique_classes = data[1].unique()\n",
    "\n",
    "# Create a new dataframe with sampled data\n",
    "sampled_data = pd.DataFrame(columns=[0, 1])\n",
    "\n",
    "# Sample uniformly from each class\n",
    "for cls in unique_classes:\n",
    "    class_data = data[data[1] == cls].sample(n=num_instances_per_class, random_state=42)\n",
    "    sampled_data = pd.concat([sampled_data, class_data], ignore_index=True)\n",
    "\n",
    "# Shuffle the sampled data\n",
    "all_data = shuffle(sampled_data, random_state=42).reset_index(drop=True)\n",
    "\n",
    "def load_image(image_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Load image from file, convert to JPEG, and encode as base64.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            # Convert image to RGB mode if it's not\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            # Save image to a bytes buffer as JPEG\n",
    "            buffer = io.BytesIO()\n",
    "            img.save(buffer, format=\"JPEG\", quality=85)  # You can adjust quality as needed\n",
    "            \n",
    "            # Encode the JPEG image as base64\n",
    "            return base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "vision_prompt = f\"\"\"\n",
    "Given the image, identify the class. Use the following list of possible classes for your prediction It should be one of the : {expected_classes}. Be attentive to subtle details as some classes may appear similar. Provide your answer in the following JSON format:\n",
    "{{\"prediction\": \"class_name\"}}\n",
    "Replace \"class_name\" with the appropriate class from the list above based on your analysis of the image.\n",
    "The labels should be entered exactly as they are in the list above i.e., {expected_classes}.\n",
    "The response should start with {{ and contain only a JSON object (as specified above) and no other text.\n",
    "\"\"\"\n",
    "\n",
    "request_times = []\n",
    "\n",
    "async def get_image_informations_gpt(session, inputs: dict) -> dict:\n",
    "    \"\"\"Invoke GPT-4 Vision model with image and prompt.\"\"\"\n",
    "    global request_times\n",
    "    \n",
    "    while True:\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Remove old request times outside the current time window\n",
    "        while request_times and request_times[0] <= current_time - 30:\n",
    "            request_times.pop(0)\n",
    "        \n",
    "        if len(request_times) < max_requests_per_half_minute:\n",
    "            request_times.append(current_time)\n",
    "            break\n",
    "        else:\n",
    "            # If the rate limit is exceeded, wait for a short duration before checking again\n",
    "            await asyncio.sleep(1)\n",
    "    \n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    model = \"gpt-4o-2024-05-13\"\n",
    "    url = \"https://api.openai.com/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": vision_prompt},\n",
    "                    *inputs['examples'],\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{inputs['image']}\",\n",
    "                            \"detail\": \"high\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "    async with session.post(url, headers=headers, json=payload) as response:\n",
    "        result = await response.json()\n",
    "        print(result)\n",
    "        if \"choices\" in result and result[\"choices\"]:\n",
    "            return result[\"choices\"][0]['message']['content']\n",
    "        else:\n",
    "            raise Exception(\"Unexpected API response format\")\n",
    "\n",
    "async def get_image_informations_claude(inputs: dict) -> str:\n",
    "    \"\"\"Invoke Claude 3.5 Sonnet model with image and prompt.\"\"\"\n",
    "    anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    anthropic_client = Anthropic(api_key=anthropic_api_key)\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": vision_prompt},\n",
    "                *[\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\",\n",
    "                            \"media_type\": \"image/jpeg\",\n",
    "                            \"data\": ex['image_url']['url'].split(',')[1] if ex['type'] == 'image_url' else ex['source']['data']\n",
    "                        }\n",
    "                    }\n",
    "                    if ex['type'] in ['image_url', 'image'] else ex\n",
    "                    for ex in inputs['examples']\n",
    "                ],\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": \"image/jpeg\",\n",
    "                        \"data\": inputs['image']\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = anthropic_client.messages.create(\n",
    "        model=\"claude-3-sonnet-20240229\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0.3,\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.content[0].text\n",
    "\n",
    "async def process_image(session, i, number_of_shots, all_data_results, model_type):\n",
    "    try:\n",
    "        image_path = all_data[0][i]\n",
    "        image_base64 = load_image(image_path)\n",
    "        if image_base64 is None:\n",
    "            raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "        \n",
    "        examples = []\n",
    "\n",
    "        # Get the number of rows in all_data\n",
    "        num_rows = len(all_data)\n",
    "\n",
    "        # Select random indices from the dataframe\n",
    "        random_indices = random.sample([idx for idx in range(num_rows) if idx != i], number_of_shots)\n",
    "\n",
    "        for j in random_indices:\n",
    "            example_image_path = all_data[0][j]\n",
    "            example_image_base64 = load_image(example_image_path)\n",
    "            if example_image_base64 is not None:\n",
    "                if model_type == \"gpt\":\n",
    "                    examples.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{example_image_base64}\", \"detail\": \"high\"}})\n",
    "                elif model_type == \"claude\":\n",
    "                    examples.append({\n",
    "                        \"type\": \"image\",\n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\",\n",
    "                            \"media_type\": \"image/jpeg\",\n",
    "                            \"data\": example_image_base64\n",
    "                        }\n",
    "                    })\n",
    "                examples.append({\"type\": \"text\", \"text\": f'{{\"prediction\": \"{all_data.at[j, 1]}\"}}' })\n",
    "\n",
    "        if model_type == \"gpt\":\n",
    "            prediction = await get_image_informations_gpt(session, {\"image\": image_base64, \"examples\": examples})\n",
    "        elif model_type == \"claude\":\n",
    "            prediction = await get_image_informations_claude({\"image\": image_base64, \"examples\": examples})\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = json.loads(prediction)['prediction']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {all_data[0][i]}: {str(e)}\")\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = 'NA'\n",
    "\n",
    "async def process_images_for_shots(number_of_shots, all_data_results, model_type):\n",
    "    if model_type == \"gpt\":\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            tasks = []\n",
    "            for i in range(len(all_data)):\n",
    "                task = asyncio.ensure_future(process_image(session, i, number_of_shots, all_data_results, model_type))\n",
    "                tasks.append(task)\n",
    "            await asyncio.gather(*tasks)\n",
    "    elif model_type == \"claude\":\n",
    "        for i in range(len(all_data)):\n",
    "            await process_image(None, i, number_of_shots, all_data_results, model_type)\n",
    "\n",
    "async def main():\n",
    "    all_data_results = all_data.copy(deep=True)\n",
    "    all_data_results.columns = all_data_results.columns.map(str)\n",
    "\n",
    "    for number_of_shots in [2]:  # [0, 1, 2, 4, 8]:\n",
    "        await process_images_for_shots(number_of_shots, all_data_results, model_type)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = f\"results_{model_type}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save results to the model-specific directory\n",
    "    output_file = os.path.join(output_dir, f\"SBRD_{model_type}.csv\")\n",
    "    all_data_results.to_csv(output_file)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API and Utility Functions\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import time\n",
    "from anthropic import Anthropic\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def load_image(image_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Load image from file, convert to JPEG, and encode as base64.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            buffer = io.BytesIO()\n",
    "            img.save(buffer, format=\"JPEG\", quality=85)\n",
    "            return base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "class RateLimiter:\n",
    "    def __init__(self, max_requests, time_window):\n",
    "        self.max_requests = max_requests\n",
    "        self.time_window = time_window\n",
    "        self.request_times = []\n",
    "\n",
    "    async def wait(self):\n",
    "        while True:\n",
    "            current_time = time.time()\n",
    "            self.request_times = [t for t in self.request_times if t > current_time - self.time_window]\n",
    "            if len(self.request_times) < self.max_requests:\n",
    "                self.request_times.append(current_time)\n",
    "                break\n",
    "            await asyncio.sleep(0.1)\n",
    "\n",
    "class GPTAPI:\n",
    "    def __init__(self, api_key, model=\"gpt-4o-2024-05-13\"):\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        self.url = \"https://api.openai.com/v1/chat/completions\"\n",
    "        self.headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "        }\n",
    "        self.rate_limiter = RateLimiter(max_requests=5, time_window=30)\n",
    "\n",
    "    async def get_image_information(self, session, inputs: dict) -> str:\n",
    "        await self.rate_limiter.wait()\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": inputs['prompt']},\n",
    "                        *inputs['examples'],\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{inputs['image']}\",\n",
    "                                \"detail\": \"high\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 4096\n",
    "        }\n",
    "        async with session.post(self.url, headers=self.headers, json=payload) as response:\n",
    "            result = await response.json()\n",
    "            if \"choices\" in result and result[\"choices\"]:\n",
    "                return result[\"choices\"][0]['message']['content']\n",
    "            else:\n",
    "                raise Exception(\"Unexpected API response format\")\n",
    "\n",
    "class ClaudeAPI:\n",
    "    def __init__(self, api_key, model=\"claude-3-sonnet-20240229\"):\n",
    "        self.client = Anthropic(api_key=api_key)\n",
    "        self.model = model\n",
    "\n",
    "    async def get_image_information(self, inputs: dict) -> str:\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": inputs['prompt']},\n",
    "                    *[\n",
    "                        {\n",
    "                            \"type\": \"image\",\n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\",\n",
    "                                \"media_type\": \"image/jpeg\",\n",
    "                                \"data\": ex['image_url']['url'].split(',')[1] if ex['type'] == 'image_url' else ex['source']['data']\n",
    "                            }\n",
    "                        }\n",
    "                        if ex['type'] in ['image_url', 'image'] else ex\n",
    "                        for ex in inputs['examples']\n",
    "                    ],\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\",\n",
    "                            \"media_type\": \"image/jpeg\",\n",
    "                            \"data\": inputs['image']\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        response = self.client.messages.create(\n",
    "            model=self.model,\n",
    "            max_tokens=1000,\n",
    "            temperature=0.3,\n",
    "            messages=messages\n",
    "        )\n",
    "        return response.content[0].text\n",
    "\n",
    "# Main Script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Set the base directory\n",
    "base_directory = 'DIRECTORY/AgEval-datasets/severity-based-rice-disease/train'\n",
    "model_type = 'gpt'\n",
    "total_samples_to_check = 10\n",
    "\n",
    "# Define the list of expected class labels\n",
    "expected_classes = ['Healthy', 'Mild Bacterial Blight', 'Mild Blast', 'Mild Brownspot', 'Mild Tungro', 'Severe Bacterial Blight', 'Severe Blast', 'Severe Brownspot', 'Severe Tungro']\n",
    "\n",
    "def load_and_prepare_data(base_directory, total_samples_to_check):\n",
    "    num_instances_per_class = int(total_samples_to_check / len(expected_classes))\n",
    "    file_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for subdir in os.listdir(base_directory):\n",
    "        if subdir == \".DS_Store\":\n",
    "            continue\n",
    "        subdir_path = os.path.join(base_directory, subdir)\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                file_paths.append(os.path.join(subdir_path, filename))\n",
    "                labels.append(subdir)\n",
    "\n",
    "    data = pd.DataFrame({0: file_paths, 1: labels})\n",
    "    sampled_data = pd.DataFrame(columns=[0, 1])\n",
    "\n",
    "    for cls in data[1].unique():\n",
    "        class_data = data[data[1] == cls].sample(n=num_instances_per_class, random_state=42)\n",
    "        sampled_data = pd.concat([sampled_data, class_data], ignore_index=True)\n",
    "\n",
    "    return shuffle(sampled_data, random_state=42).reset_index(drop=True)\n",
    "\n",
    "vision_prompt = f\"\"\"\n",
    "Given the image, identify the class. Use the following list of possible classes for your prediction It should be one of the : {expected_classes}. Be attentive to subtle details as some classes may appear similar. Provide your answer in the following JSON format:\n",
    "{{\"prediction\": \"class_name\"}}\n",
    "Replace \"class_name\" with the appropriate class from the list above based on your analysis of the image.\n",
    "The labels should be entered exactly as they are in the list above i.e., {expected_classes}.\n",
    "The response should start with {{ and contain only a JSON object (as specified above) and no other text.\n",
    "\"\"\"\n",
    "\n",
    "async def process_image(api, session, i, number_of_shots, all_data_results, all_data):\n",
    "    try:\n",
    "        image_path = all_data[0][i]\n",
    "        image_base64 = load_image(image_path)\n",
    "        if image_base64 is None:\n",
    "            raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "        \n",
    "        examples = []\n",
    "        num_rows = len(all_data)\n",
    "        random_indices = random.sample([idx for idx in range(num_rows) if idx != i], number_of_shots)\n",
    "\n",
    "        for j in random_indices:\n",
    "            example_image_path = all_data[0][j]\n",
    "            example_image_base64 = load_image(example_image_path)\n",
    "            if example_image_base64 is not None:\n",
    "                if isinstance(api, GPTAPI):\n",
    "                    examples.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{example_image_base64}\", \"detail\": \"high\"}})\n",
    "                elif isinstance(api, ClaudeAPI):\n",
    "                    examples.append({\n",
    "                        \"type\": \"image\",\n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\",\n",
    "                            \"media_type\": \"image/jpeg\",\n",
    "                            \"data\": example_image_base64\n",
    "                        }\n",
    "                    })\n",
    "                examples.append({\"type\": \"text\", \"text\": f'{{\"prediction\": \"{all_data.at[j, 1]}\"}}' })\n",
    "\n",
    "        prediction = await api.get_image_information({\"image\": image_base64, \"examples\": examples, \"prompt\": vision_prompt})\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = json.loads(prediction)['prediction']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {all_data[0][i]}: {str(e)}\")\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = 'NA'\n",
    "\n",
    "async def process_images_for_shots(api, number_of_shots, all_data_results, all_data):\n",
    "    if isinstance(api, GPTAPI):\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            tasks = []\n",
    "            for i in range(len(all_data)):\n",
    "                task = asyncio.ensure_future(process_image(api, session, i, number_of_shots, all_data_results, all_data))\n",
    "                tasks.append(task)\n",
    "            await asyncio.gather(*tasks)\n",
    "    elif isinstance(api, ClaudeAPI):\n",
    "        for i in range(len(all_data)):\n",
    "            await process_image(api, None, i, number_of_shots, all_data_results, all_data)\n",
    "\n",
    "async def main():\n",
    "    all_data = load_and_prepare_data(base_directory, total_samples_to_check)\n",
    "    all_data_results = all_data.copy(deep=True)\n",
    "    all_data_results.columns = all_data_results.columns.map(str)\n",
    "\n",
    "    if model_type == \"gpt\":\n",
    "        api = GPTAPI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    elif model_type == \"claude\":\n",
    "        api = ClaudeAPI(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "\n",
    "    for number_of_shots in [0]:  # [0, 1, 2, 4, 8]:\n",
    "        await process_images_for_shots(api, number_of_shots, all_data_results, all_data)\n",
    "    \n",
    "    output_dir = f\"results_{model_type}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_file = os.path.join(output_dir, f\"SBRD_{model_type}.csv\")\n",
    "    all_data_results.to_csv(output_file)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import time\n",
    "from anthropic import Anthropic\n",
    "from PIL import Image\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "import nest_asyncio\n",
    "from tqdm import tqdm\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def load_image(image_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Load image from file, convert to JPEG, and encode as base64.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            buffer = io.BytesIO()\n",
    "            img.save(buffer, format=\"JPEG\", quality=85)\n",
    "            return base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "class RateLimiter:\n",
    "    def __init__(self, max_requests, time_window):\n",
    "        self.max_requests = max_requests\n",
    "        self.time_window = time_window\n",
    "        self.request_times = []\n",
    "\n",
    "    async def wait(self):\n",
    "        while True:\n",
    "            current_time = time.time()\n",
    "            self.request_times = [t for t in self.request_times if t > current_time - self.time_window]\n",
    "            if len(self.request_times) < self.max_requests:\n",
    "                self.request_times.append(current_time)\n",
    "                break\n",
    "            await asyncio.sleep(0.1)\n",
    "\n",
    "class GPTAPI:\n",
    "    def __init__(self, api_key, model=\"gpt-4o-2024-05-13\"):\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        self.url = \"https://api.openai.com/v1/chat/completions\"\n",
    "        self.headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "        }\n",
    "        self.rate_limiter = RateLimiter(max_requests=5, time_window=30)\n",
    "\n",
    "    async def get_image_information(self, session, inputs: dict) -> str:\n",
    "        await self.rate_limiter.wait()\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": inputs['prompt']},\n",
    "                        *inputs['examples'],\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{inputs['image']}\",\n",
    "                                \"detail\": \"high\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 300\n",
    "        }\n",
    "        async with session.post(self.url, headers=self.headers, json=payload) as response:\n",
    "            result = await response.json()\n",
    "            if \"choices\" in result and result[\"choices\"]:\n",
    "                return result[\"choices\"][0]['message']['content']\n",
    "            else:\n",
    "                raise Exception(f\"Unexpected API response format: {result}\")\n",
    "\n",
    "class ClaudeAPI:\n",
    "    def __init__(self, api_key, model=\"claude-3-sonnet-20240229\"):\n",
    "        self.client = Anthropic(api_key=api_key)\n",
    "        self.model = model\n",
    "\n",
    "    async def get_image_information(self, inputs: dict) -> str:\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": inputs['prompt']},\n",
    "                    *[\n",
    "                        {\n",
    "                            \"type\": \"image\",\n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\",\n",
    "                                \"media_type\": \"image/jpeg\",\n",
    "                                \"data\": ex['image_url']['url'].split(',')[1] if ex['type'] == 'image_url' else ex['source']['data']\n",
    "                            }\n",
    "                        }\n",
    "                        if ex['type'] in ['image_url', 'image'] else ex\n",
    "                        for ex in inputs['examples']\n",
    "                    ],\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\",\n",
    "                            \"media_type\": \"image/jpeg\",\n",
    "                            \"data\": inputs['image']\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        response = self.client.messages.create(\n",
    "            model=self.model,\n",
    "            max_tokens=1000,\n",
    "            temperature=0.3,\n",
    "            messages=messages\n",
    "        )\n",
    "        return response.content[0].text\n",
    "\n",
    "# Set the base directory\n",
    "base_directory = 'DIRECTORY/AgEval-datasets/severity-based-rice-disease/train'\n",
    "model_type = 'gpt'\n",
    "total_samples_to_check = 10\n",
    "\n",
    "# Define the list of expected class labels\n",
    "expected_classes = ['Healthy', 'Mild Bacterial Blight', 'Mild Blast', 'Mild Brownspot', 'Mild Tungro', 'Severe Bacterial Blight', 'Severe Blast', 'Severe Brownspot', 'Severe Tungro']\n",
    "\n",
    "def load_and_prepare_data(base_directory, total_samples_to_check):\n",
    "    num_instances_per_class = int(total_samples_to_check / len(expected_classes))\n",
    "    file_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for subdir in os.listdir(base_directory):\n",
    "        if subdir == \".DS_Store\":\n",
    "            continue\n",
    "        subdir_path = os.path.join(base_directory, subdir)\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                file_paths.append(os.path.join(subdir_path, filename))\n",
    "                labels.append(subdir)\n",
    "\n",
    "    data = pd.DataFrame({0: file_paths, 1: labels})\n",
    "    sampled_data = pd.DataFrame(columns=[0, 1])\n",
    "\n",
    "    for cls in data[1].unique():\n",
    "        class_data = data[data[1] == cls].sample(n=num_instances_per_class, random_state=42)\n",
    "        sampled_data = pd.concat([sampled_data, class_data], ignore_index=True)\n",
    "\n",
    "    return shuffle(sampled_data, random_state=42).reset_index(drop=True)\n",
    "\n",
    "vision_prompt = f\"\"\"\n",
    "Given the image, identify the class. Use the following list of possible classes for your prediction It should be one of the : {expected_classes}. Be attentive to subtle details as some classes may appear similar. Provide your answer in the following JSON format:\n",
    "{{\"prediction\": \"class_name\"}}\n",
    "Replace \"class_name\" with the appropriate class from the list above based on your analysis of the image.\n",
    "The labels should be entered exactly as they are in the list above i.e., {expected_classes}.\n",
    "The response should start with {{ and contain only a JSON object (as specified above) and no other text.\n",
    "\"\"\"\n",
    "\n",
    "async def process_image(api, session, i, number_of_shots, all_data_results, all_data):\n",
    "    try:\n",
    "        image_path = all_data[0][i]\n",
    "        image_base64 = load_image(image_path)\n",
    "        if image_base64 is None:\n",
    "            raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "        \n",
    "        examples = []\n",
    "        num_rows = len(all_data)\n",
    "        random_indices = random.sample([idx for idx in range(num_rows) if idx != i], number_of_shots)\n",
    "\n",
    "        for j in random_indices:\n",
    "            example_image_path = all_data[0][j]\n",
    "            example_image_base64 = load_image(example_image_path)\n",
    "            if example_image_base64 is not None:\n",
    "                if isinstance(api, GPTAPI):\n",
    "                    examples.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{example_image_base64}\", \"detail\": \"high\"}})\n",
    "                elif isinstance(api, ClaudeAPI):\n",
    "                    examples.append({\n",
    "                        \"type\": \"image\",\n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\",\n",
    "                            \"media_type\": \"image/jpeg\",\n",
    "                            \"data\": example_image_base64\n",
    "                        }\n",
    "                    })\n",
    "                examples.append({\"type\": \"text\", \"text\": f'{{\"prediction\": \"{all_data.at[j, 1]}\"}}' })\n",
    "\n",
    "        if isinstance(api, GPTAPI):\n",
    "            prediction = await api.get_image_information(session, {\"image\": image_base64, \"examples\": examples, \"prompt\": vision_prompt})\n",
    "        else:\n",
    "            prediction = await api.get_image_information({\"image\": image_base64, \"examples\": examples, \"prompt\": vision_prompt})\n",
    "        \n",
    "        try:\n",
    "            parsed_prediction = json.loads(prediction)['prediction']\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error parsing JSON for image {image_path}. API response: {prediction}\")\n",
    "            parsed_prediction = 'Error: Invalid JSON'\n",
    "        except KeyError:\n",
    "            print(f\"Missing 'prediction' key for image {image_path}. API response: {prediction}\")\n",
    "            parsed_prediction = 'Error: Missing prediction'\n",
    "\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = parsed_prediction\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {all_data[0][i]}: {str(e)}\")\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = f'Error: {str(e)}'\n",
    "\n",
    "async def process_images_for_shots(api, number_of_shots, all_data_results, all_data):\n",
    "    if isinstance(api, GPTAPI):\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            tasks = []\n",
    "            for i in tqdm(range(len(all_data)), desc=f\"Processing {number_of_shots}-shot samples\"):\n",
    "                task = asyncio.ensure_future(process_image(api, session, i, number_of_shots, all_data_results, all_data))\n",
    "                tasks.append(task)\n",
    "            await asyncio.gather(*tasks)\n",
    "    elif isinstance(api, ClaudeAPI):\n",
    "        for i in tqdm(range(len(all_data)), desc=f\"Processing {number_of_shots}-shot samples\"):\n",
    "            await process_image(api, None, i, number_of_shots, all_data_results, all_data)\n",
    "\n",
    "async def main():\n",
    "    all_data = load_and_prepare_data(base_directory, total_samples_to_check)\n",
    "    all_data_results = all_data.copy(deep=True)\n",
    "    all_data_results.columns = all_data_results.columns.map(str)\n",
    "\n",
    "    if model_type == \"gpt\":\n",
    "        api = GPTAPI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    elif model_type == \"claude\":\n",
    "        api = ClaudeAPI(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "\n",
    "    for number_of_shots in [0]:  # [0, 1, 2, 4, 8]:\n",
    "        await process_images_for_shots(api, number_of_shots, all_data_results, all_data)\n",
    "    \n",
    "    output_dir = f\"results_{model_type}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_file = os.path.join(output_dir, f\"SBRD_{model_type}.csv\")\n",
    "    all_data_results.to_csv(output_file)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import time\n",
    "from anthropic import Anthropic\n",
    "from PIL import Image\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "import nest_asyncio\n",
    "from tqdm import tqdm\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def load_image(image_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Load image from file, convert to JPEG, and encode as base64.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            buffer = io.BytesIO()\n",
    "            img.save(buffer, format=\"JPEG\", quality=85)\n",
    "            return base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "class RateLimiter:\n",
    "    def __init__(self, max_requests, time_window):\n",
    "        self.max_requests = max_requests\n",
    "        self.time_window = time_window\n",
    "        self.request_times = []\n",
    "\n",
    "    async def wait(self):\n",
    "        while True:\n",
    "            current_time = time.time()\n",
    "            self.request_times = [t for t in self.request_times if t > current_time - self.time_window]\n",
    "            if len(self.request_times) < self.max_requests:\n",
    "                self.request_times.append(current_time)\n",
    "                break\n",
    "            await asyncio.sleep(0.1)\n",
    "\n",
    "class GPTAPI:\n",
    "    def __init__(self, api_key, model=\"gpt-4o-2024-05-13\"):\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        self.url = \"https://api.openai.com/v1/chat/completions\"\n",
    "        self.headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "        }\n",
    "        self.rate_limiter = RateLimiter(max_requests=5, time_window=30)\n",
    "\n",
    "    async def get_image_information(self, inputs: dict) -> str:\n",
    "        await self.rate_limiter.wait()\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": inputs['prompt']},\n",
    "                        *inputs['examples'],\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{inputs['image']}\",\n",
    "                                \"detail\": \"high\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 300\n",
    "        }\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.post(self.url, headers=self.headers, json=payload) as response:\n",
    "                result = await response.json()\n",
    "                if \"choices\" in result and result[\"choices\"]:\n",
    "                    return result[\"choices\"][0]['message']['content']\n",
    "                else:\n",
    "                    raise Exception(f\"Unexpected API response format: {result}\")\n",
    "\n",
    "class ClaudeAPI:\n",
    "    def __init__(self, api_key, model=\"claude-3-sonnet-20240229\"):\n",
    "        self.client = Anthropic(api_key=api_key)\n",
    "        self.model = model\n",
    "\n",
    "    async def get_image_information(self, inputs: dict) -> str:\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": inputs['prompt']},\n",
    "                    *[\n",
    "                        {\n",
    "                            \"type\": \"image\",\n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\",\n",
    "                                \"media_type\": \"image/jpeg\",\n",
    "                                \"data\": ex['image_url']['url'].split(',')[1] if ex['type'] == 'image_url' else ex['source']['data']\n",
    "                            }\n",
    "                        }\n",
    "                        if ex['type'] in ['image_url', 'image'] else ex\n",
    "                        for ex in inputs['examples']\n",
    "                    ],\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\",\n",
    "                            \"media_type\": \"image/jpeg\",\n",
    "                            \"data\": inputs['image']\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        response = self.client.messages.create(\n",
    "            model=self.model,\n",
    "            max_tokens=1000,\n",
    "            temperature=0.3,\n",
    "            messages=messages\n",
    "        )\n",
    "        return response.content[0].text\n",
    "\n",
    "# Set the base directory\n",
    "base_directory = 'DIRECTORY/AgEval-datasets/severity-based-rice-disease/train'\n",
    "model_type = 'claude'  # Change this to 'claude' to use Claude API\n",
    "total_samples_to_check = 10\n",
    "\n",
    "# Define the list of expected class labels\n",
    "expected_classes = ['Healthy', 'Mild Bacterial Blight', 'Mild Blast', 'Mild Brownspot', 'Mild Tungro', 'Severe Bacterial Blight', 'Severe Blast', 'Severe Brownspot', 'Severe Tungro']\n",
    "\n",
    "def load_and_prepare_data(base_directory, total_samples_to_check):\n",
    "    num_instances_per_class = int(total_samples_to_check / len(expected_classes))\n",
    "    file_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for subdir in os.listdir(base_directory):\n",
    "        if subdir == \".DS_Store\":\n",
    "            continue\n",
    "        subdir_path = os.path.join(base_directory, subdir)\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                file_paths.append(os.path.join(subdir_path, filename))\n",
    "                labels.append(subdir)\n",
    "\n",
    "    data = pd.DataFrame({0: file_paths, 1: labels})\n",
    "    sampled_data = pd.DataFrame(columns=[0, 1])\n",
    "\n",
    "    for cls in data[1].unique():\n",
    "        class_data = data[data[1] == cls].sample(n=num_instances_per_class, random_state=42)\n",
    "        sampled_data = pd.concat([sampled_data, class_data], ignore_index=True)\n",
    "\n",
    "    return shuffle(sampled_data, random_state=42).reset_index(drop=True)\n",
    "\n",
    "vision_prompt = f\"\"\"\n",
    "Given the image, identify the class. Use the following list of possible classes for your prediction It should be one of the : {expected_classes}. Be attentive to subtle details as some classes may appear similar. Provide your answer in the following JSON format:\n",
    "{{\"prediction\": \"class_name\"}}\n",
    "Replace \"class_name\" with the appropriate class from the list above based on your analysis of the image.\n",
    "The labels should be entered exactly as they are in the list above i.e., {expected_classes}.\n",
    "The response should start with {{ and contain only a JSON object (as specified above) and no other text.\n",
    "\"\"\"\n",
    "\n",
    "async def process_image(api, i, number_of_shots, all_data_results, all_data):\n",
    "    try:\n",
    "        image_path = all_data[0][i]\n",
    "        image_base64 = load_image(image_path)\n",
    "        if image_base64 is None:\n",
    "            raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "        \n",
    "        examples = []\n",
    "        num_rows = len(all_data)\n",
    "        random_indices = random.sample([idx for idx in range(num_rows) if idx != i], number_of_shots)\n",
    "\n",
    "        for j in random_indices:\n",
    "            example_image_path = all_data[0][j]\n",
    "            example_image_base64 = load_image(example_image_path)\n",
    "            if example_image_base64 is not None:\n",
    "                if isinstance(api, GPTAPI):\n",
    "                    examples.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{example_image_base64}\", \"detail\": \"high\"}})\n",
    "                elif isinstance(api, ClaudeAPI):\n",
    "                    examples.append({\n",
    "                        \"type\": \"image\",\n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\",\n",
    "                            \"media_type\": \"image/jpeg\",\n",
    "                            \"data\": example_image_base64\n",
    "                        }\n",
    "                    })\n",
    "                examples.append({\"type\": \"text\", \"text\": f'{{\"prediction\": \"{all_data.at[j, 1]}\"}}' })\n",
    "\n",
    "        prediction = await api.get_image_information({\"image\": image_base64, \"examples\": examples, \"prompt\": vision_prompt})\n",
    "        \n",
    "        try:\n",
    "            parsed_prediction = json.loads(prediction)['prediction']\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error parsing JSON for image {image_path}. API response: {prediction}\")\n",
    "            parsed_prediction = 'Error: Invalid JSON'\n",
    "        except KeyError:\n",
    "            print(f\"Missing 'prediction' key for image {image_path}. API response: {prediction}\")\n",
    "            parsed_prediction = 'Error: Missing prediction'\n",
    "\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = parsed_prediction\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {all_data[0][i]}: {str(e)}\")\n",
    "        all_data_results.at[i, f\"# of Shots {number_of_shots}\"] = f'Error: {str(e)}'\n",
    "\n",
    "async def process_images_for_shots(api, number_of_shots, all_data_results, all_data):\n",
    "    tasks = []\n",
    "    for i in tqdm(range(len(all_data)), desc=f\"Processing {number_of_shots}-shot samples\"):\n",
    "        task = asyncio.ensure_future(process_image(api, i, number_of_shots, all_data_results, all_data))\n",
    "        tasks.append(task)\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "async def main():\n",
    "    all_data = load_and_prepare_data(base_directory, total_samples_to_check)\n",
    "    all_data_results = all_data.copy(deep=True)\n",
    "    all_data_results.columns = all_data_results.columns.map(str)\n",
    "\n",
    "    if model_type == \"gpt\":\n",
    "        api = GPTAPI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    elif model_type == \"claude\":\n",
    "        api = ClaudeAPI(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "\n",
    "    for number_of_shots in [0]:  # [0, 1, 2, 4, 8]:\n",
    "        await process_images_for_shots(api, number_of_shots, all_data_results, all_data)\n",
    "    \n",
    "    output_dir = f\"results_{model_type}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_file = os.path.join(output_dir, f\"SBRD_{model_type}.csv\")\n",
    "    all_data_results.to_csv(output_file)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt4o-env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
